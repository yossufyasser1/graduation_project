{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d054240b",
   "metadata": {
    "id": "d054240b",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Pre-process images with ResNet521 weights ported from VQA 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "DvW051aCj12e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DvW051aCj12e",
    "outputId": "3cb0386f-97ee-4312-9d58-f51feb820f87",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'Visual-question-answering-model'...\n",
      "remote: Enumerating objects: 55, done.\u001b[K\n",
      "remote: Counting objects: 100% (55/55), done.\u001b[K\n",
      "remote: Compressing objects: 100% (45/45), done.\u001b[K\n",
      "remote: Total 55 (delta 8), reused 21 (delta 7), pack-reused 0\u001b[K\n",
      "Unpacking objects: 100% (55/55), 4.21 MiB | 10.33 MiB/s, done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/yossufyasser1/Visual-question-answering-model.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "A8nRW4wzj7p6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A8nRW4wzj7p6",
    "outputId": "84e126e0-9c15-40fe-c33c-c77ba535f798",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Visual-question-answering-model\n"
     ]
    }
   ],
   "source": [
    "%cd /Visual-question-answering-model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8eb79be0-7987-4924-8a91-167d5f6bb3f9",
   "metadata": {
    "id": "8eb79be0-7987-4924-8a91-167d5f6bb3f9",
    "outputId": "d7417bc5-dbbd-44c9-8074-ecc2252f2688",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.0.1)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (4.65.0)\n",
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.12.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (585.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m585.9/585.9 MB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting h5py\n",
      "  Downloading h5py-3.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m61.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting efficientnet_pytorch\n",
      "  Downloading efficientnet_pytorch-0.7.1.tar.gz (21 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch) (4.5.0)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.2)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.32.0-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m67.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting tensorflow-estimator<2.13,>=2.12.0\n",
      "  Downloading tensorflow_estimator-2.12.0-py2.py3-none-any.whl (440 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m440.7/440.7 kB\u001b[0m \u001b[31m109.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tensorboard<2.13,>=2.12\n",
      "  Downloading tensorboard-2.12.3-py3-none-any.whl (5.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m63.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting jax>=0.3.15\n",
      "  Downloading jax-0.4.10.tar.gz (1.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m98.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting opt-einsum>=2.3.2\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.6.3)\n",
      "Collecting gast<=0.4.0,>=0.2.1\n",
      "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Collecting flatbuffers>=2.0\n",
      "  Downloading flatbuffers-23.5.9-py2.py3-none-any.whl (26 kB)\n",
      "Collecting termcolor>=1.1.0\n",
      "  Downloading termcolor-2.3.0-py3-none-any.whl (6.9 kB)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3\n",
      "  Downloading protobuf-4.23.1-cp37-abi3-manylinux2014_x86_64.whl (304 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m304.5/304.5 kB\u001b[0m \u001b[31m44.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting absl-py>=1.0.0\n",
      "  Downloading absl_py-1.4.0-py3-none-any.whl (126 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.5/126.5 kB\u001b[0m \u001b[31m31.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting grpcio<2.0,>=1.24.3\n",
      "  Downloading grpcio-1.54.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m61.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from tensorflow) (23.0)\n",
      "Collecting keras<2.13,>=2.12.0\n",
      "  Downloading keras-2.12.0-py2.py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m94.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting google-pasta>=0.1.1\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting wrapt<1.15,>=1.11.0\n",
      "  Downloading wrapt-1.14.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (77 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting numpy<1.24,>=1.22\n",
      "  Downloading numpy-1.23.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m52.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from tensorflow) (65.6.3)\n",
      "Collecting libclang>=13.0.0\n",
      "  Downloading libclang-16.0.0-py2.py3-none-manylinux2010_x86_64.whl (22.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22.9/22.9 MB\u001b[0m \u001b[31m50.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow) (0.38.4)\n",
      "Requirement already satisfied: scipy>=1.7 in /opt/conda/lib/python3.10/site-packages (from jax>=0.3.15->tensorflow) (1.10.1)\n",
      "Collecting ml-dtypes>=0.1.0\n",
      "  Downloading ml_dtypes-0.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (190 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.6/190.6 kB\u001b[0m \u001b[31m36.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tensorboard-data-server<0.8.0,>=0.7.0\n",
      "  Downloading tensorboard_data_server-0.7.0-py3-none-manylinux2014_x86_64.whl (6.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m66.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting google-auth-oauthlib<1.1,>=0.5\n",
      "  Downloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\n",
      "Collecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.4.3-py3-none-any.whl (93 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.9/93.9 kB\u001b[0m \u001b[31m31.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.29.0)\n",
      "Collecting google-auth<3,>=1.6.3\n",
      "  Downloading google_auth-2.18.1-py2.py3-none-any.whl (178 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m178.9/178.9 kB\u001b[0m \u001b[31m37.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting werkzeug>=1.0.1\n",
      "  Downloading Werkzeug-2.3.4-py3-none-any.whl (242 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.5/242.5 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n",
      "Collecting rsa<5,>=3.1.4\n",
      "  Downloading rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0\n",
      "  Downloading cachetools-5.3.0-py3-none-any.whl (9.3 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Downloading pyasn1_modules-0.3.0-py2.py3-none-any.whl (181 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m181.3/181.3 kB\u001b[0m \u001b[31m36.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: urllib3<2.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (1.26.15)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (2023.5.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (3.4)\n",
      "Collecting pyasn1<0.6.0,>=0.4.6\n",
      "  Downloading pyasn1-0.5.0-py2.py3-none-any.whl (83 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.9/83.9 kB\u001b[0m \u001b[31m28.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m151.7/151.7 kB\u001b[0m \u001b[31m33.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: efficientnet_pytorch, jax\n",
      "  Building wheel for efficientnet_pytorch (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for efficientnet_pytorch: filename=efficientnet_pytorch-0.7.1-py3-none-any.whl size=16429 sha256=5486d6ea6079b9f373678af018095b84e81510d2991db8bd56043499219f0be7\n",
      "  Stored in directory: /root/.cache/pip/wheels/03/3f/e9/911b1bc46869644912bda90a56bcf7b960f20b5187feea3baf\n",
      "  Building wheel for jax (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for jax: filename=jax-0.4.10-py3-none-any.whl size=1480503 sha256=be90cdd673423af30401e9e27b2022c8b0307843fb35c9cc6cfb9de667b10ad8\n",
      "  Stored in directory: /root/.cache/pip/wheels/2f/04/51/ebc9c5225f0a0df1e56c231c1f4c9b7afd3e024ebb492eed99\n",
      "Successfully built efficientnet_pytorch jax\n",
      "Installing collected packages: libclang, flatbuffers, wrapt, werkzeug, termcolor, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard-data-server, pyasn1, protobuf, oauthlib, numpy, markdown, keras, grpcio, google-pasta, gast, cachetools, absl-py, rsa, requests-oauthlib, pyasn1-modules, opt-einsum, ml-dtypes, h5py, jax, google-auth, efficientnet_pytorch, google-auth-oauthlib, tensorboard, tensorflow\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.24.3\n",
      "    Uninstalling numpy-1.24.3:\n",
      "      Successfully uninstalled numpy-1.24.3\n",
      "Successfully installed absl-py-1.4.0 cachetools-5.3.0 efficientnet_pytorch-0.7.1 flatbuffers-23.5.9 gast-0.4.0 google-auth-2.18.1 google-auth-oauthlib-1.0.0 google-pasta-0.2.0 grpcio-1.54.2 h5py-3.8.0 jax-0.4.10 keras-2.12.0 libclang-16.0.0 markdown-3.4.3 ml-dtypes-0.1.0 numpy-1.23.5 oauthlib-3.2.2 opt-einsum-3.3.0 protobuf-4.23.1 pyasn1-0.5.0 pyasn1-modules-0.3.0 requests-oauthlib-1.3.1 rsa-4.9 tensorboard-2.12.3 tensorboard-data-server-0.7.0 tensorflow-2.12.0 tensorflow-estimator-2.12.0 tensorflow-io-gcs-filesystem-0.32.0 termcolor-2.3.0 werkzeug-2.3.4 wrapt-1.14.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install torch tqdm tensorflow  h5py efficientnet_pytorch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "vWcOZ9orkFAI",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "id": "vWcOZ9orkFAI",
    "outputId": "916e676a-1008-49f0-b3ab-13eae630f3f2",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-24 16:38:59.625814: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-24 16:39:00.371827: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.utils.data\n",
    "import torchvision.models as models\n",
    "from tqdm import tqdm\n",
    "\n",
    "import config\n",
    "import data\n",
    "import utils\n",
    "from resnet import resnet as caffe_resnet\n",
    "import tensorflow as tf\n",
    "import json\n",
    "import os\n",
    "import os.path\n",
    "import re\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "\n",
    "from PIL import Image\n",
    "import h5py\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "import torchvision.transforms as transforms\n",
    "from collections import Counter\n",
    "import itertools\n",
    "import config\n",
    "import utils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a3748a7f-c579-4faf-9b13-197aa083d0ec",
   "metadata": {
    "id": "a3748a7f-c579-4faf-9b13-197aa083d0ec",
    "outputId": "c9408510-3336-4af6-93c8-b4a6a51da697",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "Suggested packages:\n",
      "  zip\n",
      "The following NEW packages will be installed:\n",
      "  unzip\n",
      "0 upgraded, 1 newly installed, 0 to remove and 7 not upgraded.\n",
      "Need to get 168 kB of archives.\n",
      "After this operation, 593 kB of additional disk space will be used.\n",
      "Get:1 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 unzip amd64 6.0-25ubuntu1.1 [168 kB]\n",
      "Fetched 168 kB in 1s (271 kB/s)\n",
      "debconf: delaying package configuration, since apt-utils is not installed\n",
      "Selecting previously unselected package unzip.\n",
      "(Reading database ... 19436 files and directories currently installed.)\n",
      "Preparing to unpack .../unzip_6.0-25ubuntu1.1_amd64.deb ...\n",
      "Unpacking unzip (6.0-25ubuntu1.1) ...\n",
      "Setting up unzip (6.0-25ubuntu1.1) ...\n",
      "Processing triggers for mime-support (3.64ubuntu1) ...\n"
     ]
    }
   ],
   "source": [
    "!apt-get install unzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "t_WQKWUqrdd0",
   "metadata": {
    "id": "t_WQKWUqrdd0",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/cvmlp/vqa/mscoco/vqa/v2_Questions_Train_mscoco.zip\n",
      "7239401/7239401 [==============================] - 7s 1us/step\n"
     ]
    }
   ],
   "source": [
    "_URL = 'https://s3.amazonaws.com/cvmlp/vqa/mscoco/vqa/v2_Questions_Train_mscoco.zip'\n",
    "zip_dir = tf.keras.utils.get_file('/QUEStrain2014.zip', origin=_URL, extract=False,archive_format='auto')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b6c660c1-c127-4ea0-b335-1bae8ce1ec32",
   "metadata": {
    "id": "b6c660c1-c127-4ea0-b335-1bae8ce1ec32",
    "tags": []
   },
   "outputs": [],
   "source": [
    "fname = '/QUEStrain2014.zip'\n",
    "!unzip -q $fname -d /Visual-question-answering-model/ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0iRMp5iBsBai",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0iRMp5iBsBai",
    "outputId": "071a36ed-f47e-4a3e-906c-9049f5a71d70",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from http://images.cocodataset.org/zips/train2014.zip\n",
      "13510573713/13510573713 [==============================] - 1222s 0us/step\n"
     ]
    }
   ],
   "source": [
    "_URL = 'http://images.cocodataset.org/zips/train2014.zip'\n",
    "zip_dir = tf.keras.utils.get_file('/MSCOCOTRAIN2014.zip', origin=_URL, extract=False,archive_format='auto')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b9ff50a1-71c0-4ab3-a2ca-3b0991623b9b",
   "metadata": {
    "id": "b9ff50a1-71c0-4ab3-a2ca-3b0991623b9b",
    "tags": []
   },
   "outputs": [],
   "source": [
    "fname = '/MSCOCOTRAIN2014.zip'\n",
    "!unzip -q $fname -d /Visual-question-answering-model/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1wTWY44EvEks",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1wTWY44EvEks",
    "outputId": "8b4bfc40-8c22-4864-8fb1-68cbe4b2a713",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from http://images.cocodataset.org/zips/val2014.zip\n",
      "6645013297/6645013297 [==============================] - 531s 0us/step\n"
     ]
    }
   ],
   "source": [
    "_URL = 'http://images.cocodataset.org/zips/val2014.zip'\n",
    "zip_dir = tf.keras.utils.get_file('/MSCOCOVAL12014.zip', origin=_URL, extract=False,archive_format='auto')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "74c3ae62-c458-4f00-ad90-9305f86fc0ec",
   "metadata": {
    "id": "74c3ae62-c458-4f00-ad90-9305f86fc0ec",
    "tags": []
   },
   "outputs": [],
   "source": [
    "fname = '/MSCOCOVAL12014.zip'\n",
    "!unzip -q $fname -d /Visual-question-answering-model/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a69ad260-e4ca-45ee-8030-dd4ba0f73e8a",
   "metadata": {
    "id": "a69ad260-e4ca-45ee-8030-dd4ba0f73e8a",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/cvmlp/vqa/mscoco/vqa/v2_Questions_Val_mscoco.zip\n",
      "3494929/3494929 [==============================] - 1s 0us/step\n"
     ]
    }
   ],
   "source": [
    "_URL = 'https://s3.amazonaws.com/cvmlp/vqa/mscoco/vqa/v2_Questions_Val_mscoco.zip'\n",
    "zip_dir = tf.keras.utils.get_file('/QUESVAL2014.zip', origin=_URL, extract=False,archive_format='auto')\n",
    "fname = '/QUESVAL2014.zip'\n",
    "!unzip -q $fname -d /Visual-question-answering-model/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7adca965-b4e7-4d43-97c8-346105300858",
   "metadata": {
    "id": "7adca965-b4e7-4d43-97c8-346105300858",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/cvmlp/vqa/mscoco/vqa/v2_Annotations_Val_mscoco.zip\n",
      "10518930/10518930 [==============================] - 1s 0us/step\n"
     ]
    }
   ],
   "source": [
    "_URL = 'https://s3.amazonaws.com/cvmlp/vqa/mscoco/vqa/v2_Annotations_Val_mscoco.zip'\n",
    "zip_dir = tf.keras.utils.get_file('/ANNOTVAL2014.zip', origin=_URL, extract=False,archive_format='auto')\n",
    "fname = '/ANNOTVAL2014.zip'\n",
    "!unzip -q $fname -d /Visual-question-answering-model/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "81be435e-dd53-43e4-a1e9-4018c0fbfb9d",
   "metadata": {
    "id": "81be435e-dd53-43e4-a1e9-4018c0fbfb9d",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/snagiri/ECE285_Jarvis_ProjectA/releases/download/v1.0/50epoch.pth\n",
      "276298398/276298398 [==============================] - 5s 0us/step\n"
     ]
    }
   ],
   "source": [
    "_URL = 'https://github.com/snagiri/ECE285_Jarvis_ProjectA/releases/download/v1.0/50epoch.pth'\n",
    "zip_dir = tf.keras.utils.get_file('/Visual-question-answering-model/MSCOCOVAL2014.pth', origin=_URL, extract=False,archive_format='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "35615b18-285f-4b9d-94aa-d5c9cf4f0257",
   "metadata": {
    "id": "35615b18-285f-4b9d-94aa-d5c9cf4f0257",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/cvmlp/vqa/mscoco/vqa/v2_Annotations_Train_mscoco.zip\n",
      "21708861/21708861 [==============================] - 2s 0us/step\n"
     ]
    }
   ],
   "source": [
    "_URL = 'https://s3.amazonaws.com/cvmlp/vqa/mscoco/vqa/v2_Annotations_Train_mscoco.zip'\n",
    "zip_dir = tf.keras.utils.get_file('/ANNOTTrain2014.zip', origin=_URL, extract=False,archive_format='auto')\n",
    "fname = '/ANNOTTrain2014.zip'\n",
    "!unzip -q $fname -d /Visual-question-answering-model/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0d5754ce-34f9-4e01-9bdc-0fdd7d9e8591",
   "metadata": {
    "id": "0d5754ce-34f9-4e01-9bdc-0fdd7d9e8591",
    "outputId": "835680dd-2d3d-4aad-dae7-f66bf34e1f6b",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "The following additional packages will be installed:\n",
      "  binutils binutils-common binutils-x86-64-linux-gnu cpp cpp-9 dirmngr\n",
      "  dpkg-dev fakeroot g++ g++-9 gcc gcc-9 gcc-9-base gnupg gnupg-l10n\n",
      "  gnupg-utils gpg-agent gpg-wks-client gpg-wks-server gpgsm\n",
      "  libalgorithm-diff-perl libalgorithm-diff-xs-perl libalgorithm-merge-perl\n",
      "  libasan5 libatomic1 libbinutils libcc1-0 libctf-nobfd0 libctf0 libdpkg-perl\n",
      "  libfakeroot libfile-fcntllock-perl libgcc-9-dev libisl22 libitm1 libksba8\n",
      "  liblocale-gettext-perl liblsan0 libmpc3 libmpfr6 libnpth0 libquadmath0\n",
      "  libstdc++-9-dev libtsan0 libubsan1 make patch pinentry-curses xz-utils\n",
      "Suggested packages:\n",
      "  binutils-doc cpp-doc gcc-9-locales pinentry-gnome3 tor debian-keyring\n",
      "  g++-multilib g++-9-multilib gcc-9-doc gcc-multilib manpages-dev autoconf\n",
      "  automake libtool flex bison gdb gcc-doc gcc-9-multilib parcimonie xloadimage\n",
      "  scdaemon bzr libstdc++-9-doc make-doc ed diffutils-doc pinentry-doc\n",
      "The following NEW packages will be installed:\n",
      "  binutils binutils-common binutils-x86-64-linux-gnu build-essential cpp cpp-9\n",
      "  dirmngr dpkg-dev fakeroot g++ g++-9 gcc gcc-9 gcc-9-base gnupg gnupg-l10n\n",
      "  gnupg-utils gpg-agent gpg-wks-client gpg-wks-server gpgsm\n",
      "  libalgorithm-diff-perl libalgorithm-diff-xs-perl libalgorithm-merge-perl\n",
      "  libasan5 libatomic1 libbinutils libcc1-0 libctf-nobfd0 libctf0 libdpkg-perl\n",
      "  libfakeroot libfile-fcntllock-perl libgcc-9-dev libisl22 libitm1 libksba8\n",
      "  liblocale-gettext-perl liblsan0 libmpc3 libmpfr6 libnpth0 libquadmath0\n",
      "  libstdc++-9-dev libtsan0 libubsan1 make patch pinentry-curses xz-utils\n",
      "0 upgraded, 50 newly installed, 0 to remove and 7 not upgraded.\n",
      "Need to get 41.6 MB of archives.\n",
      "After this operation, 179 MB of additional disk space will be used.\n",
      "Get:1 http://archive.ubuntu.com/ubuntu focal/main amd64 liblocale-gettext-perl amd64 1.07-4 [17.1 kB]\n",
      "Get:2 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 xz-utils amd64 5.2.4-1ubuntu1.1 [82.6 kB]\n",
      "Get:3 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 binutils-common amd64 2.34-6ubuntu1.5 [207 kB]\n",
      "Get:4 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libbinutils amd64 2.34-6ubuntu1.5 [475 kB]\n",
      "Get:5 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libctf-nobfd0 amd64 2.34-6ubuntu1.5 [47.4 kB]\n",
      "Get:6 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libctf0 amd64 2.34-6ubuntu1.5 [46.6 kB]\n",
      "Get:7 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 binutils-x86-64-linux-gnu amd64 2.34-6ubuntu1.5 [1613 kB]\n",
      "Get:8 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 binutils amd64 2.34-6ubuntu1.5 [3372 B]\n",
      "Get:9 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 gcc-9-base amd64 9.4.0-1ubuntu1~20.04.1 [19.4 kB]\n",
      "Get:10 http://archive.ubuntu.com/ubuntu focal/main amd64 libisl22 amd64 0.22.1-1 [592 kB]\n",
      "Get:11 http://archive.ubuntu.com/ubuntu focal/main amd64 libmpfr6 amd64 4.0.2-1 [240 kB]\n",
      "Get:12 http://archive.ubuntu.com/ubuntu focal/main amd64 libmpc3 amd64 1.1.0-1 [40.8 kB]\n",
      "Get:13 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 cpp-9 amd64 9.4.0-1ubuntu1~20.04.1 [7500 kB]\n",
      "Get:14 http://archive.ubuntu.com/ubuntu focal/main amd64 cpp amd64 4:9.3.0-1ubuntu2 [27.6 kB]\n",
      "Get:15 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libcc1-0 amd64 10.3.0-1ubuntu1~20.04 [48.8 kB]\n",
      "Get:16 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libitm1 amd64 10.3.0-1ubuntu1~20.04 [26.2 kB]\n",
      "Get:17 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libatomic1 amd64 10.3.0-1ubuntu1~20.04 [9284 B]\n",
      "Get:18 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libasan5 amd64 9.4.0-1ubuntu1~20.04.1 [2751 kB]\n",
      "Get:19 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 liblsan0 amd64 10.3.0-1ubuntu1~20.04 [835 kB]\n",
      "Get:20 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libtsan0 amd64 10.3.0-1ubuntu1~20.04 [2009 kB]\n",
      "Get:21 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libubsan1 amd64 10.3.0-1ubuntu1~20.04 [784 kB]\n",
      "Get:22 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libquadmath0 amd64 10.3.0-1ubuntu1~20.04 [146 kB]\n",
      "Get:23 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libgcc-9-dev amd64 9.4.0-1ubuntu1~20.04.1 [2359 kB]\n",
      "Get:24 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 gcc-9 amd64 9.4.0-1ubuntu1~20.04.1 [8274 kB]\n",
      "Get:25 http://archive.ubuntu.com/ubuntu focal/main amd64 gcc amd64 4:9.3.0-1ubuntu2 [5208 B]\n",
      "Get:26 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libstdc++-9-dev amd64 9.4.0-1ubuntu1~20.04.1 [1722 kB]\n",
      "Get:27 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 g++-9 amd64 9.4.0-1ubuntu1~20.04.1 [8420 kB]\n",
      "Get:28 http://archive.ubuntu.com/ubuntu focal/main amd64 g++ amd64 4:9.3.0-1ubuntu2 [1604 B]\n",
      "Get:29 http://archive.ubuntu.com/ubuntu focal/main amd64 make amd64 4.2.1-1.2 [162 kB]\n",
      "Get:30 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libdpkg-perl all 1.19.7ubuntu3.2 [231 kB]\n",
      "Get:31 http://archive.ubuntu.com/ubuntu focal/main amd64 patch amd64 2.7.6-6 [105 kB]\n",
      "Get:32 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 dpkg-dev all 1.19.7ubuntu3.2 [679 kB]\n",
      "Get:33 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 build-essential amd64 12.8ubuntu1.1 [4664 B]\n",
      "Get:34 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libksba8 amd64 1.3.5-2ubuntu0.20.04.2 [95.2 kB]\n",
      "Get:35 http://archive.ubuntu.com/ubuntu focal/main amd64 libnpth0 amd64 1.6-1 [7736 B]\n",
      "Get:36 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 dirmngr amd64 2.2.19-3ubuntu2.2 [330 kB]\n",
      "Get:37 http://archive.ubuntu.com/ubuntu focal/main amd64 libfakeroot amd64 1.24-1 [25.7 kB]\n",
      "Get:38 http://archive.ubuntu.com/ubuntu focal/main amd64 fakeroot amd64 1.24-1 [62.6 kB]\n",
      "Get:39 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 gnupg-l10n all 2.2.19-3ubuntu2.2 [51.7 kB]\n",
      "Get:40 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 gnupg-utils amd64 2.2.19-3ubuntu2.2 [481 kB]\n",
      "Get:41 http://archive.ubuntu.com/ubuntu focal/main amd64 pinentry-curses amd64 1.1.0-3build1 [36.3 kB]\n",
      "Get:42 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 gpg-agent amd64 2.2.19-3ubuntu2.2 [232 kB]\n",
      "Get:43 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 gpg-wks-client amd64 2.2.19-3ubuntu2.2 [97.4 kB]\n",
      "Get:44 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 gpg-wks-server amd64 2.2.19-3ubuntu2.2 [90.2 kB]\n",
      "Get:45 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 gpgsm amd64 2.2.19-3ubuntu2.2 [217 kB]\n",
      "Get:46 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 gnupg all 2.2.19-3ubuntu2.2 [259 kB]\n",
      "Get:47 http://archive.ubuntu.com/ubuntu focal/main amd64 libalgorithm-diff-perl all 1.19.03-2 [46.6 kB]\n",
      "Get:48 http://archive.ubuntu.com/ubuntu focal/main amd64 libalgorithm-diff-xs-perl amd64 0.04-6 [11.3 kB]\n",
      "Get:49 http://archive.ubuntu.com/ubuntu focal/main amd64 libalgorithm-merge-perl all 0.08-3 [12.0 kB]\n",
      "Get:50 http://archive.ubuntu.com/ubuntu focal/main amd64 libfile-fcntllock-perl amd64 0.22-3build4 [33.1 kB]\n",
      "Fetched 41.6 MB in 2s (18.0 MB/s)                  \n",
      "debconf: delaying package configuration, since apt-utils is not installed\n",
      "Selecting previously unselected package liblocale-gettext-perl.\n",
      "(Reading database ... 19454 files and directories currently installed.)\n",
      "Preparing to unpack .../00-liblocale-gettext-perl_1.07-4_amd64.deb ...\n",
      "Unpacking liblocale-gettext-perl (1.07-4) ...\n",
      "Selecting previously unselected package xz-utils.\n",
      "Preparing to unpack .../01-xz-utils_5.2.4-1ubuntu1.1_amd64.deb ...\n",
      "Unpacking xz-utils (5.2.4-1ubuntu1.1) ...\n",
      "Selecting previously unselected package binutils-common:amd64.\n",
      "Preparing to unpack .../02-binutils-common_2.34-6ubuntu1.5_amd64.deb ...\n",
      "Unpacking binutils-common:amd64 (2.34-6ubuntu1.5) ...\n",
      "Selecting previously unselected package libbinutils:amd64.\n",
      "Preparing to unpack .../03-libbinutils_2.34-6ubuntu1.5_amd64.deb ...\n",
      "Unpacking libbinutils:amd64 (2.34-6ubuntu1.5) ...\n",
      "Selecting previously unselected package libctf-nobfd0:amd64.\n",
      "Preparing to unpack .../04-libctf-nobfd0_2.34-6ubuntu1.5_amd64.deb ...\n",
      "Unpacking libctf-nobfd0:amd64 (2.34-6ubuntu1.5) ...\n",
      "Selecting previously unselected package libctf0:amd64.\n",
      "Preparing to unpack .../05-libctf0_2.34-6ubuntu1.5_amd64.deb ...\n",
      "Unpacking libctf0:amd64 (2.34-6ubuntu1.5) ...\n",
      "Selecting previously unselected package binutils-x86-64-linux-gnu.\n",
      "Preparing to unpack .../06-binutils-x86-64-linux-gnu_2.34-6ubuntu1.5_amd64.deb ...\n",
      "Unpacking binutils-x86-64-linux-gnu (2.34-6ubuntu1.5) ...\n",
      "Selecting previously unselected package binutils.\n",
      "Preparing to unpack .../07-binutils_2.34-6ubuntu1.5_amd64.deb ...\n",
      "Unpacking binutils (2.34-6ubuntu1.5) ...\n",
      "Selecting previously unselected package gcc-9-base:amd64.\n",
      "Preparing to unpack .../08-gcc-9-base_9.4.0-1ubuntu1~20.04.1_amd64.deb ...\n",
      "Unpacking gcc-9-base:amd64 (9.4.0-1ubuntu1~20.04.1) ...\n",
      "Selecting previously unselected package libisl22:amd64.\n",
      "Preparing to unpack .../09-libisl22_0.22.1-1_amd64.deb ...\n",
      "Unpacking libisl22:amd64 (0.22.1-1) ...\n",
      "Selecting previously unselected package libmpfr6:amd64.\n",
      "Preparing to unpack .../10-libmpfr6_4.0.2-1_amd64.deb ...\n",
      "Unpacking libmpfr6:amd64 (4.0.2-1) ...\n",
      "Selecting previously unselected package libmpc3:amd64.\n",
      "Preparing to unpack .../11-libmpc3_1.1.0-1_amd64.deb ...\n",
      "Unpacking libmpc3:amd64 (1.1.0-1) ...\n",
      "Selecting previously unselected package cpp-9.\n",
      "Preparing to unpack .../12-cpp-9_9.4.0-1ubuntu1~20.04.1_amd64.deb ...\n",
      "Unpacking cpp-9 (9.4.0-1ubuntu1~20.04.1) ...\n",
      "Selecting previously unselected package cpp.\n",
      "Preparing to unpack .../13-cpp_4%3a9.3.0-1ubuntu2_amd64.deb ...\n",
      "Unpacking cpp (4:9.3.0-1ubuntu2) ...\n",
      "Selecting previously unselected package libcc1-0:amd64.\n",
      "Preparing to unpack .../14-libcc1-0_10.3.0-1ubuntu1~20.04_amd64.deb ...\n",
      "Unpacking libcc1-0:amd64 (10.3.0-1ubuntu1~20.04) ...\n",
      "Selecting previously unselected package libitm1:amd64.\n",
      "Preparing to unpack .../15-libitm1_10.3.0-1ubuntu1~20.04_amd64.deb ...\n",
      "Unpacking libitm1:amd64 (10.3.0-1ubuntu1~20.04) ...\n",
      "Selecting previously unselected package libatomic1:amd64.\n",
      "Preparing to unpack .../16-libatomic1_10.3.0-1ubuntu1~20.04_amd64.deb ...\n",
      "Unpacking libatomic1:amd64 (10.3.0-1ubuntu1~20.04) ...\n",
      "Selecting previously unselected package libasan5:amd64.\n",
      "Preparing to unpack .../17-libasan5_9.4.0-1ubuntu1~20.04.1_amd64.deb ...\n",
      "Unpacking libasan5:amd64 (9.4.0-1ubuntu1~20.04.1) ...\n",
      "Selecting previously unselected package liblsan0:amd64.\n",
      "Preparing to unpack .../18-liblsan0_10.3.0-1ubuntu1~20.04_amd64.deb ...\n",
      "Unpacking liblsan0:amd64 (10.3.0-1ubuntu1~20.04) ...\n",
      "Selecting previously unselected package libtsan0:amd64.\n",
      "Preparing to unpack .../19-libtsan0_10.3.0-1ubuntu1~20.04_amd64.deb ...\n",
      "Unpacking libtsan0:amd64 (10.3.0-1ubuntu1~20.04) ...\n",
      "Selecting previously unselected package libubsan1:amd64.\n",
      "Preparing to unpack .../20-libubsan1_10.3.0-1ubuntu1~20.04_amd64.deb ...\n",
      "Unpacking libubsan1:amd64 (10.3.0-1ubuntu1~20.04) ...\n",
      "Selecting previously unselected package libquadmath0:amd64.\n",
      "Preparing to unpack .../21-libquadmath0_10.3.0-1ubuntu1~20.04_amd64.deb ...\n",
      "Unpacking libquadmath0:amd64 (10.3.0-1ubuntu1~20.04) ...\n",
      "Selecting previously unselected package libgcc-9-dev:amd64.\n",
      "Preparing to unpack .../22-libgcc-9-dev_9.4.0-1ubuntu1~20.04.1_amd64.deb ...\n",
      "Unpacking libgcc-9-dev:amd64 (9.4.0-1ubuntu1~20.04.1) ...\n",
      "Selecting previously unselected package gcc-9.\n",
      "Preparing to unpack .../23-gcc-9_9.4.0-1ubuntu1~20.04.1_amd64.deb ...\n",
      "Unpacking gcc-9 (9.4.0-1ubuntu1~20.04.1) ...\n",
      "Selecting previously unselected package gcc.\n",
      "Preparing to unpack .../24-gcc_4%3a9.3.0-1ubuntu2_amd64.deb ...\n",
      "Unpacking gcc (4:9.3.0-1ubuntu2) ...\n",
      "Selecting previously unselected package libstdc++-9-dev:amd64.\n",
      "Preparing to unpack .../25-libstdc++-9-dev_9.4.0-1ubuntu1~20.04.1_amd64.deb ...\n",
      "Unpacking libstdc++-9-dev:amd64 (9.4.0-1ubuntu1~20.04.1) ...\n",
      "Selecting previously unselected package g++-9.\n",
      "Preparing to unpack .../26-g++-9_9.4.0-1ubuntu1~20.04.1_amd64.deb ...\n",
      "Unpacking g++-9 (9.4.0-1ubuntu1~20.04.1) ...\n",
      "Selecting previously unselected package g++.\n",
      "Preparing to unpack .../27-g++_4%3a9.3.0-1ubuntu2_amd64.deb ...\n",
      "Unpacking g++ (4:9.3.0-1ubuntu2) ...\n",
      "Selecting previously unselected package make.\n",
      "Preparing to unpack .../28-make_4.2.1-1.2_amd64.deb ...\n",
      "Unpacking make (4.2.1-1.2) ...\n",
      "Selecting previously unselected package libdpkg-perl.\n",
      "Preparing to unpack .../29-libdpkg-perl_1.19.7ubuntu3.2_all.deb ...\n",
      "Unpacking libdpkg-perl (1.19.7ubuntu3.2) ...\n",
      "Selecting previously unselected package patch.\n",
      "Preparing to unpack .../30-patch_2.7.6-6_amd64.deb ...\n",
      "Unpacking patch (2.7.6-6) ...\n",
      "Selecting previously unselected package dpkg-dev.\n",
      "Preparing to unpack .../31-dpkg-dev_1.19.7ubuntu3.2_all.deb ...\n",
      "Unpacking dpkg-dev (1.19.7ubuntu3.2) ...\n",
      "Selecting previously unselected package build-essential.\n",
      "Preparing to unpack .../32-build-essential_12.8ubuntu1.1_amd64.deb ...\n",
      "Unpacking build-essential (12.8ubuntu1.1) ...\n",
      "Selecting previously unselected package libksba8:amd64.\n",
      "Preparing to unpack .../33-libksba8_1.3.5-2ubuntu0.20.04.2_amd64.deb ...\n",
      "Unpacking libksba8:amd64 (1.3.5-2ubuntu0.20.04.2) ...\n",
      "Selecting previously unselected package libnpth0:amd64.\n",
      "Preparing to unpack .../34-libnpth0_1.6-1_amd64.deb ...\n",
      "Unpacking libnpth0:amd64 (1.6-1) ...\n",
      "Selecting previously unselected package dirmngr.\n",
      "Preparing to unpack .../35-dirmngr_2.2.19-3ubuntu2.2_amd64.deb ...\n",
      "Unpacking dirmngr (2.2.19-3ubuntu2.2) ...\n",
      "Selecting previously unselected package libfakeroot:amd64.\n",
      "Preparing to unpack .../36-libfakeroot_1.24-1_amd64.deb ...\n",
      "Unpacking libfakeroot:amd64 (1.24-1) ...\n",
      "Selecting previously unselected package fakeroot.\n",
      "Preparing to unpack .../37-fakeroot_1.24-1_amd64.deb ...\n",
      "Unpacking fakeroot (1.24-1) ...\n",
      "Selecting previously unselected package gnupg-l10n.\n",
      "Preparing to unpack .../38-gnupg-l10n_2.2.19-3ubuntu2.2_all.deb ...\n",
      "Unpacking gnupg-l10n (2.2.19-3ubuntu2.2) ...\n",
      "Selecting previously unselected package gnupg-utils.\n",
      "Preparing to unpack .../39-gnupg-utils_2.2.19-3ubuntu2.2_amd64.deb ...\n",
      "Unpacking gnupg-utils (2.2.19-3ubuntu2.2) ...\n",
      "Selecting previously unselected package pinentry-curses.\n",
      "Preparing to unpack .../40-pinentry-curses_1.1.0-3build1_amd64.deb ...\n",
      "Unpacking pinentry-curses (1.1.0-3build1) ...\n",
      "Selecting previously unselected package gpg-agent.\n",
      "Preparing to unpack .../41-gpg-agent_2.2.19-3ubuntu2.2_amd64.deb ...\n",
      "Unpacking gpg-agent (2.2.19-3ubuntu2.2) ...\n",
      "Selecting previously unselected package gpg-wks-client.\n",
      "Preparing to unpack .../42-gpg-wks-client_2.2.19-3ubuntu2.2_amd64.deb ...\n",
      "Unpacking gpg-wks-client (2.2.19-3ubuntu2.2) ...\n",
      "Selecting previously unselected package gpg-wks-server.\n",
      "Preparing to unpack .../43-gpg-wks-server_2.2.19-3ubuntu2.2_amd64.deb ...\n",
      "Unpacking gpg-wks-server (2.2.19-3ubuntu2.2) ...\n",
      "Selecting previously unselected package gpgsm.\n",
      "Preparing to unpack .../44-gpgsm_2.2.19-3ubuntu2.2_amd64.deb ...\n",
      "Unpacking gpgsm (2.2.19-3ubuntu2.2) ...\n",
      "Selecting previously unselected package gnupg.\n",
      "Preparing to unpack .../45-gnupg_2.2.19-3ubuntu2.2_all.deb ...\n",
      "Unpacking gnupg (2.2.19-3ubuntu2.2) ...\n",
      "Selecting previously unselected package libalgorithm-diff-perl.\n",
      "Preparing to unpack .../46-libalgorithm-diff-perl_1.19.03-2_all.deb ...\n",
      "Unpacking libalgorithm-diff-perl (1.19.03-2) ...\n",
      "Selecting previously unselected package libalgorithm-diff-xs-perl.\n",
      "Preparing to unpack .../47-libalgorithm-diff-xs-perl_0.04-6_amd64.deb ...\n",
      "Unpacking libalgorithm-diff-xs-perl (0.04-6) ...\n",
      "Selecting previously unselected package libalgorithm-merge-perl.\n",
      "Preparing to unpack .../48-libalgorithm-merge-perl_0.08-3_all.deb ...\n",
      "Unpacking libalgorithm-merge-perl (0.08-3) ...\n",
      "Selecting previously unselected package libfile-fcntllock-perl.\n",
      "Preparing to unpack .../49-libfile-fcntllock-perl_0.22-3build4_amd64.deb ...\n",
      "Unpacking libfile-fcntllock-perl (0.22-3build4) ...\n",
      "Setting up libksba8:amd64 (1.3.5-2ubuntu0.20.04.2) ...\n",
      "Setting up pinentry-curses (1.1.0-3build1) ...\n",
      "Setting up libfile-fcntllock-perl (0.22-3build4) ...\n",
      "Setting up libalgorithm-diff-perl (1.19.03-2) ...\n",
      "Setting up gpgsm (2.2.19-3ubuntu2.2) ...\n",
      "Setting up binutils-common:amd64 (2.34-6ubuntu1.5) ...\n",
      "Setting up libctf-nobfd0:amd64 (2.34-6ubuntu1.5) ...\n",
      "Setting up libnpth0:amd64 (1.6-1) ...\n",
      "Setting up libfakeroot:amd64 (1.24-1) ...\n",
      "Setting up fakeroot (1.24-1) ...\n",
      "update-alternatives: using /usr/bin/fakeroot-sysv to provide /usr/bin/fakeroot (fakeroot) in auto mode\n",
      "update-alternatives: warning: skip creation of /usr/share/man/man1/fakeroot.1.gz because associated file /usr/share/man/man1/fakeroot-sysv.1.gz (of link group fakeroot) doesn't exist\n",
      "update-alternatives: warning: skip creation of /usr/share/man/man1/faked.1.gz because associated file /usr/share/man/man1/faked-sysv.1.gz (of link group fakeroot) doesn't exist\n",
      "update-alternatives: warning: skip creation of /usr/share/man/es/man1/fakeroot.1.gz because associated file /usr/share/man/es/man1/fakeroot-sysv.1.gz (of link group fakeroot) doesn't exist\n",
      "update-alternatives: warning: skip creation of /usr/share/man/es/man1/faked.1.gz because associated file /usr/share/man/es/man1/faked-sysv.1.gz (of link group fakeroot) doesn't exist\n",
      "update-alternatives: warning: skip creation of /usr/share/man/fr/man1/fakeroot.1.gz because associated file /usr/share/man/fr/man1/fakeroot-sysv.1.gz (of link group fakeroot) doesn't exist\n",
      "update-alternatives: warning: skip creation of /usr/share/man/fr/man1/faked.1.gz because associated file /usr/share/man/fr/man1/faked-sysv.1.gz (of link group fakeroot) doesn't exist\n",
      "update-alternatives: warning: skip creation of /usr/share/man/sv/man1/fakeroot.1.gz because associated file /usr/share/man/sv/man1/fakeroot-sysv.1.gz (of link group fakeroot) doesn't exist\n",
      "update-alternatives: warning: skip creation of /usr/share/man/sv/man1/faked.1.gz because associated file /usr/share/man/sv/man1/faked-sysv.1.gz (of link group fakeroot) doesn't exist\n",
      "Setting up dirmngr (2.2.19-3ubuntu2.2) ...\n",
      "Created symlink /etc/systemd/user/sockets.target.wants/dirmngr.socket → /usr/lib/systemd/user/dirmngr.socket.\n",
      "Setting up make (4.2.1-1.2) ...\n",
      "Setting up libmpfr6:amd64 (4.0.2-1) ...\n",
      "Setting up gnupg-l10n (2.2.19-3ubuntu2.2) ...\n",
      "Setting up xz-utils (5.2.4-1ubuntu1.1) ...\n",
      "update-alternatives: using /usr/bin/xz to provide /usr/bin/lzma (lzma) in auto mode\n",
      "update-alternatives: warning: skip creation of /usr/share/man/man1/lzma.1.gz because associated file /usr/share/man/man1/xz.1.gz (of link group lzma) doesn't exist\n",
      "update-alternatives: warning: skip creation of /usr/share/man/man1/unlzma.1.gz because associated file /usr/share/man/man1/unxz.1.gz (of link group lzma) doesn't exist\n",
      "update-alternatives: warning: skip creation of /usr/share/man/man1/lzcat.1.gz because associated file /usr/share/man/man1/xzcat.1.gz (of link group lzma) doesn't exist\n",
      "update-alternatives: warning: skip creation of /usr/share/man/man1/lzmore.1.gz because associated file /usr/share/man/man1/xzmore.1.gz (of link group lzma) doesn't exist\n",
      "update-alternatives: warning: skip creation of /usr/share/man/man1/lzless.1.gz because associated file /usr/share/man/man1/xzless.1.gz (of link group lzma) doesn't exist\n",
      "update-alternatives: warning: skip creation of /usr/share/man/man1/lzdiff.1.gz because associated file /usr/share/man/man1/xzdiff.1.gz (of link group lzma) doesn't exist\n",
      "update-alternatives: warning: skip creation of /usr/share/man/man1/lzcmp.1.gz because associated file /usr/share/man/man1/xzcmp.1.gz (of link group lzma) doesn't exist\n",
      "update-alternatives: warning: skip creation of /usr/share/man/man1/lzgrep.1.gz because associated file /usr/share/man/man1/xzgrep.1.gz (of link group lzma) doesn't exist\n",
      "update-alternatives: warning: skip creation of /usr/share/man/man1/lzegrep.1.gz because associated file /usr/share/man/man1/xzegrep.1.gz (of link group lzma) doesn't exist\n",
      "update-alternatives: warning: skip creation of /usr/share/man/man1/lzfgrep.1.gz because associated file /usr/share/man/man1/xzfgrep.1.gz (of link group lzma) doesn't exist\n",
      "Setting up libquadmath0:amd64 (10.3.0-1ubuntu1~20.04) ...\n",
      "Setting up libmpc3:amd64 (1.1.0-1) ...\n",
      "Setting up libatomic1:amd64 (10.3.0-1ubuntu1~20.04) ...\n",
      "Setting up patch (2.7.6-6) ...\n",
      "Setting up libdpkg-perl (1.19.7ubuntu3.2) ...\n",
      "Setting up libubsan1:amd64 (10.3.0-1ubuntu1~20.04) ...\n",
      "Setting up libisl22:amd64 (0.22.1-1) ...\n",
      "Setting up libbinutils:amd64 (2.34-6ubuntu1.5) ...\n",
      "Setting up libalgorithm-diff-xs-perl (0.04-6) ...\n",
      "Setting up libcc1-0:amd64 (10.3.0-1ubuntu1~20.04) ...\n",
      "Setting up liblocale-gettext-perl (1.07-4) ...\n",
      "Setting up liblsan0:amd64 (10.3.0-1ubuntu1~20.04) ...\n",
      "Setting up libitm1:amd64 (10.3.0-1ubuntu1~20.04) ...\n",
      "Setting up gcc-9-base:amd64 (9.4.0-1ubuntu1~20.04.1) ...\n",
      "Setting up libalgorithm-merge-perl (0.08-3) ...\n",
      "Setting up gnupg-utils (2.2.19-3ubuntu2.2) ...\n",
      "Setting up libtsan0:amd64 (10.3.0-1ubuntu1~20.04) ...\n",
      "Setting up libctf0:amd64 (2.34-6ubuntu1.5) ...\n",
      "Setting up gpg-agent (2.2.19-3ubuntu2.2) ...\n",
      "Created symlink /etc/systemd/user/sockets.target.wants/gpg-agent-browser.socket → /usr/lib/systemd/user/gpg-agent-browser.socket.\n",
      "Created symlink /etc/systemd/user/sockets.target.wants/gpg-agent-extra.socket → /usr/lib/systemd/user/gpg-agent-extra.socket.\n",
      "Created symlink /etc/systemd/user/sockets.target.wants/gpg-agent-ssh.socket → /usr/lib/systemd/user/gpg-agent-ssh.socket.\n",
      "Created symlink /etc/systemd/user/sockets.target.wants/gpg-agent.socket → /usr/lib/systemd/user/gpg-agent.socket.\n",
      "Setting up gpg-wks-client (2.2.19-3ubuntu2.2) ...\n",
      "Setting up libasan5:amd64 (9.4.0-1ubuntu1~20.04.1) ...\n",
      "Setting up gpg-wks-server (2.2.19-3ubuntu2.2) ...\n",
      "Setting up gnupg (2.2.19-3ubuntu2.2) ...\n",
      "Setting up cpp-9 (9.4.0-1ubuntu1~20.04.1) ...\n",
      "Setting up binutils-x86-64-linux-gnu (2.34-6ubuntu1.5) ...\n",
      "Setting up binutils (2.34-6ubuntu1.5) ...\n",
      "Setting up dpkg-dev (1.19.7ubuntu3.2) ...\n",
      "Setting up libgcc-9-dev:amd64 (9.4.0-1ubuntu1~20.04.1) ...\n",
      "Setting up cpp (4:9.3.0-1ubuntu2) ...\n",
      "Setting up gcc-9 (9.4.0-1ubuntu1~20.04.1) ...\n",
      "Setting up libstdc++-9-dev:amd64 (9.4.0-1ubuntu1~20.04.1) ...\n",
      "Setting up gcc (4:9.3.0-1ubuntu2) ...\n",
      "Setting up g++-9 (9.4.0-1ubuntu1~20.04.1) ...\n",
      "Setting up g++ (4:9.3.0-1ubuntu2) ...\n",
      "update-alternatives: using /usr/bin/g++ to provide /usr/bin/c++ (c++) in auto mode\n",
      "update-alternatives: warning: skip creation of /usr/share/man/man1/c++.1.gz because associated file /usr/share/man/man1/g++.1.gz (of link group c++) doesn't exist\n",
      "Setting up build-essential (12.8ubuntu1.1) ...\n",
      "Processing triggers for libc-bin (2.31-0ubuntu9.9) ...\n",
      "Collecting pycocotools\n",
      "  Downloading pycocotools-2.0.6.tar.gz (24 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from pycocotools) (1.23.5)\n",
      "Collecting matplotlib>=2.1.0\n",
      "  Downloading matplotlib-3.7.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m57.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hCollecting fonttools>=4.22.0\n",
      "  Downloading fonttools-4.39.4-py3-none-any.whl (1.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m105.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools) (9.4.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools) (23.0)\n",
      "Collecting contourpy>=1.0.1\n",
      "  Downloading contourpy-1.0.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (300 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m300.3/300.3 kB\u001b[0m \u001b[31m54.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools) (2.8.2)\n",
      "Collecting cycler>=0.10\n",
      "  Downloading cycler-0.11.0-py3-none-any.whl (6.4 kB)\n",
      "Collecting pyparsing>=2.3.1\n",
      "  Downloading pyparsing-3.0.9-py3-none-any.whl (98 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.3/98.3 kB\u001b[0m \u001b[31m22.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting kiwisolver>=1.0.1\n",
      "  Downloading kiwisolver-1.4.4-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m111.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib>=2.1.0->pycocotools) (1.16.0)\n",
      "Building wheels for collected packages: pycocotools\n",
      "  Building wheel for pycocotools (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pycocotools: filename=pycocotools-2.0.6-cp310-cp310-linux_x86_64.whl size=102196 sha256=0a61aaeadc5d6ad15de44619286d6f4f35cf67331cf255606c50aecc308676c2\n",
      "  Stored in directory: /root/.cache/pip/wheels/58/e6/f9/f87c8f8be098b51b616871315318329cae12cdb618f4caac93\n",
      "Successfully built pycocotools\n",
      "Installing collected packages: pyparsing, kiwisolver, fonttools, cycler, contourpy, matplotlib, pycocotools\n",
      "Successfully installed contourpy-1.0.7 cycler-0.11.0 fonttools-4.39.4 kiwisolver-1.4.4 matplotlib-3.7.1 pycocotools-2.0.6 pyparsing-3.0.9\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!apt-get install build-essential -y\n",
    "!pip install pycocotools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "Pwo0B44S2mZy",
   "metadata": {
    "id": "Pwo0B44S2mZy",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import os.path\n",
    "import re\n",
    "from retinanet import model as retinanet\n",
    "from retinanet.dataloader import CocoDataset, CSVDataset, collater, Resizer, AspectRatioBasedSampler, Augmenter, \\\n",
    "    Normalizer\n",
    "\n",
    "from PIL import Image\n",
    "import h5py\n",
    "import torch\n",
    "import torch.utils.data as tdata\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import config\n",
    "import utils\n",
    "def get_transform(target_size, central_fraction=1.0):\n",
    "    return transforms.Compose([\n",
    "    transforms.Resize(int(target_size / central_fraction)),\n",
    "    transforms.CenterCrop(target_size),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "    std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "\n",
    "def get_loader(train=False, val=False, test=False):\n",
    "    \"\"\" Returns a data loader for the desired split \"\"\"\n",
    "    assert train + val + test == 1, 'need to set exactly one of {train, val, test} to True'\n",
    "    split = VQA(\n",
    "        path_for(train=train, val=val, test=test, question=True),\n",
    "        path_for(train=train, val=val, test=test, answer=True),\n",
    "        config.preprocessed_path,\n",
    "        answerable_only=train,\n",
    "    )\n",
    "    loader = torch.utils.data.DataLoader(\n",
    "        split,\n",
    "        batch_size=config.batch_size,\n",
    "        shuffle=train,  # only shuffle the data in training\n",
    "        pin_memory=True,\n",
    "        num_workers=config.data_workers,\n",
    "        collate_fn=collate_fn,\n",
    "    )\n",
    "    return loader\n",
    "\n",
    "\n",
    "def collate_fn(batch):\n",
    "    # put question lengths in descending order so that we can use packed sequences later\n",
    "    batch.sort(key=lambda x: x[-1], reverse=True)\n",
    "    return tdata.dataloader.default_collate(batch)\n",
    "\n",
    "\n",
    "class VQA(tdata.Dataset):\n",
    "    \"\"\" VQA dataset, open-ended \"\"\"\n",
    "    def __init__(self, questions_path, answers_path, image_features_path, answerable_only=False):\n",
    "        super(VQA, self).__init__()\n",
    "        with open(questions_path, 'r') as fd:\n",
    "            questions_json = json.load(fd)\n",
    "        with open(answers_path, 'r') as fd:\n",
    "            answers_json = json.load(fd)\n",
    "        with open(config.vocabulary_path, 'r') as fd:\n",
    "            vocab_json = json.load(fd)\n",
    "        self._check_integrity(questions_json, answers_json)\n",
    "\n",
    "        # vocab\n",
    "        self.vocab = vocab_json\n",
    "        self.token_to_index = self.vocab['question']\n",
    "        self.answer_to_index = self.vocab['answer']\n",
    "\n",
    "        # q and a\n",
    "        self.questions = list(prepare_questions(questions_json))\n",
    "        self.answers = list(prepare_answers(answers_json))\n",
    "        self.questions = [self._encode_question(q) for q in self.questions]\n",
    "        self.answers = [self._encode_answers(a) for a in self.answers]\n",
    "\n",
    "        # v\n",
    "        self.image_features_path = image_features_path\n",
    "        self.coco_id_to_index = self._create_coco_id_to_index()\n",
    "        self.coco_ids = [q['image_id'] for q in questions_json['questions']]\n",
    "\n",
    "        # only use questions that have at least one answer?\n",
    "        self.answerable_only = answerable_only\n",
    "        if self.answerable_only:\n",
    "            self.answerable = self._find_answerable()\n",
    "\n",
    "    @property\n",
    "    def max_question_length(self):\n",
    "        if not hasattr(self, '_max_length'):\n",
    "            self._max_length = max(map(len, self.questions))\n",
    "        return self._max_length\n",
    "\n",
    "    @property\n",
    "    def num_tokens(self):\n",
    "        return len(self.token_to_index) + 1  # add 1 for <unknown> token at index 0\n",
    "\n",
    "    def _create_coco_id_to_index(self):\n",
    "        \"\"\" Create a mapping from a COCO image id into the corresponding index into the h5 file \"\"\"\n",
    "        with h5py.File(self.image_features_path, 'r') as features_file:\n",
    "            coco_ids = features_file['ids'][()]\n",
    "        coco_id_to_index = {id: i for i, id in enumerate(coco_ids)}\n",
    "        return coco_id_to_index\n",
    "\n",
    "    def _check_integrity(self, questions, answers):\n",
    "        \"\"\" Verify that we are using the correct data \"\"\"\n",
    "        qa_pairs = list(zip(questions['questions'], answers['annotations']))\n",
    "        assert all(q['question_id'] == a['question_id'] for q, a in qa_pairs), 'Questions not aligned with answers'\n",
    "        assert all(q['image_id'] == a['image_id'] for q, a in qa_pairs), 'Image id of question and answer don\\'t match'\n",
    "        assert questions['data_type'] == answers['data_type'], 'Mismatched data types'\n",
    "        assert questions['data_subtype'] == answers['data_subtype'], 'Mismatched data subtypes'\n",
    "\n",
    "    def _find_answerable(self):\n",
    "        \"\"\" Create a list of indices into questions that will have at least one answer that is in the vocab \"\"\"\n",
    "        answerable = []\n",
    "        for i, answers in enumerate(self.answers):\n",
    "            answer_has_index = len(answers.nonzero()) > 0\n",
    "            # store the indices of anything that is answerable\n",
    "            if answer_has_index:\n",
    "                answerable.append(i)\n",
    "        return answerable\n",
    "\n",
    "    def _encode_question(self, question):\n",
    "        \"\"\" Turn a question into a vector of indices and a question length \"\"\"\n",
    "        vec = torch.zeros(self.max_question_length).long()\n",
    "        for i, token in enumerate(question):\n",
    "            index = self.token_to_index.get(token, 0)\n",
    "            vec[i] = index\n",
    "        return vec, len(question)\n",
    "\n",
    "    def _encode_answers(self, answers):\n",
    "        \"\"\" Turn an answer into a vector \"\"\"\n",
    "        # answer vec will be a vector of answer counts to determine which answers will contribute to the loss.\n",
    "        # this should be multiplied with 0.1 * negative log-likelihoods that a model produces and then summed up\n",
    "        # to get the loss that is weighted by how many humans gave that answer\n",
    "        answer_vec = torch.zeros(len(self.answer_to_index))\n",
    "        for answer in answers:\n",
    "            index = self.answer_to_index.get(answer)\n",
    "            if index is not None:\n",
    "                answer_vec[index] += 1\n",
    "        return answer_vec\n",
    "\n",
    "    def _load_image(self, image_id):\n",
    "        \"\"\" Load an image \"\"\"\n",
    "        if not hasattr(self, 'features_file'):\n",
    "            # Loading the h5 file has to be done here and not in __init__ because when the DataLoader\n",
    "            # forks for multiple works, every child would use the same file object and fail\n",
    "            # Having multiple readers using different file objects is fine though, so we just init in here.\n",
    "            self.features_file = h5py.File(self.image_features_path, 'r')\n",
    "        index = self.coco_id_to_index[image_id]\n",
    "        dataset = self.features_file['features']\n",
    "        img = dataset[index].astype('float32')\n",
    "        return torch.from_numpy(img)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        if self.answerable_only:\n",
    "            # change of indices to only address answerable questions\n",
    "            item = self.answerable[item]\n",
    "\n",
    "        q, q_length = self.questions[item]\n",
    "        a = self.answers[item]\n",
    "        image_id = self.coco_ids[item]\n",
    "        v = self._load_image(image_id)\n",
    "        # since batches are re-ordered for PackedSequence's, the original question order is lost\n",
    "        # we return `item` so that the order of (v, q, a) triples can be restored if desired\n",
    "        # without shuffling in the dataloader, these will be in the order that they appear in the q and a json's.\n",
    "        return v, q, a, item, q_length\n",
    "\n",
    "    def __len__(self):\n",
    "        if self.answerable_only:\n",
    "            return len(self.answerable)\n",
    "        else:\n",
    "            return len(self.questions)\n",
    "\n",
    "\n",
    "# this is used for normalizing questions\n",
    "_special_chars = re.compile('[^a-z0-9 ]*')\n",
    "\n",
    "# these try to emulate the original normalization scheme for answers\n",
    "_period_strip = re.compile(r'(?!<=\\d)(\\.)(?!\\d)')\n",
    "_comma_strip = re.compile(r'(\\d)(,)(\\d)')\n",
    "_punctuation_chars = re.escape(r';/[]\"{}()=+\\_-><@`,?!')\n",
    "_punctuation = re.compile(r'([{}])'.format(re.escape(_punctuation_chars)))\n",
    "_punctuation_with_a_space = re.compile(r'(?<= )([{0}])|([{0}])(?= )'.format(_punctuation_chars))\n",
    "\n",
    "\n",
    "def prepare_questions(questions_json):\n",
    "    \"\"\" Tokenize and normalize questions from a given question json in the usual VQA format. \"\"\"\n",
    "    questions = [q['question'] for q in questions_json['questions']]\n",
    "    for question in questions:\n",
    "        question = question.lower()[:-1]\n",
    "        yield question.split(' ')\n",
    "\n",
    "\n",
    "def prepare_answers(answers_json):\n",
    "    \"\"\" Normalize answers from a given answer json in the usual VQA format. \"\"\"\n",
    "    answers = [[a['answer'] for a in ans_dict['answers']] for ans_dict in answers_json['annotations']]\n",
    "    # The only normalization that is applied to both machine generated answers as well as\n",
    "    # ground truth answers is replacing most punctuation with space (see [0] and [1]).\n",
    "    # Since potential machine generated answers are just taken from most common answers, applying the other\n",
    "    # normalizations is not needed, assuming that the human answers are already normalized.\n",
    "    # [0]: http://visualqa.org/evaluation.html\n",
    "    # [1]: https://github.com/VT-vision-lab/VQA/blob/3849b1eae04a0ffd83f56ad6f70ebd0767e09e0f/PythonEvaluationTools/vqaEvaluation/vqaEval.py#L96\n",
    "\n",
    "    def process_punctuation(s):\n",
    "        # the original is somewhat broken, so things that look odd here might just be to mimic that behaviour\n",
    "        # this version should be faster since we use re instead of repeated operations on str's\n",
    "        if _punctuation.search(s) is None:\n",
    "            return s\n",
    "        s = _punctuation_with_a_space.sub('', s)\n",
    "        if re.search(_comma_strip, s) is not None:\n",
    "            s = s.replace(',', '')\n",
    "        s = _punctuation.sub(' ', s)\n",
    "        s = _period_strip.sub('', s)\n",
    "        return s.strip()\n",
    "\n",
    "    for answer_list in answers:\n",
    "        yield list(map(process_punctuation, answer_list))\n",
    "\n",
    "\n",
    "class CocoImages(tdata.Dataset):\n",
    "    \"\"\" Dataset for MSCOCO images located in a folder on the filesystem \"\"\"\n",
    "    def __init__(self, path, transform=None):\n",
    "        super(CocoImages, self).__init__()\n",
    "        self.path = path\n",
    "        self.id_to_filename = self._find_images()\n",
    "        self.sorted_ids = sorted(self.id_to_filename.keys())  # used for deterministic iteration order\n",
    "        print('found {} images in {}'.format(len(self), self.path))\n",
    "        self.transform = transform\n",
    "\n",
    "    def _find_images(self):\n",
    "        id_to_filename = {}\n",
    "        for filename in os.listdir(self.path):\n",
    "            if not filename.endswith('.jpg'):\n",
    "                continue\n",
    "            id_and_extension = filename.split('_')[-1]\n",
    "            id = int(id_and_extension.split('.')[0])\n",
    "            id_to_filename[id] = filename\n",
    "        return id_to_filename\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        id = self.sorted_ids[item]\n",
    "        path = os.path.join(self.path, self.id_to_filename[id])\n",
    "        img = Image.open(path).convert('RGB')\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        return id, img\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sorted_ids)\n",
    "\n",
    "\n",
    "class Composite(tdata.Dataset):\n",
    "    \"\"\" Dataset that is a composite of several Dataset objects. Useful for combining splits of a dataset. \"\"\"\n",
    "    def __init__(self, *datasets):\n",
    "        self.datasets = datasets\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        current = self.datasets[0]\n",
    "        for d in self.datasets:\n",
    "            if item < len(d):\n",
    "                return d[item]\n",
    "            item -= len(d)\n",
    "        else:\n",
    "            raise IndexError('Index too large for composite dataset')\n",
    "\n",
    "    def __len__(self):\n",
    "        return sum(map(len, self.datasets))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "45b3bbc5-0285-48d9-a75d-5e7b67bbed3f",
   "metadata": {
    "id": "45b3bbc5-0285-48d9-a75d-5e7b67bbed3f",
    "tags": []
   },
   "outputs": [],
   "source": [
    "pathimg = \"/Visual-question-answering-model/train2014/\"\n",
    "pathimgval = \"/Visual-question-answering-model/val2014\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8b49037c-13e4-4ced-86db-fb1d88f37083",
   "metadata": {
    "id": "8b49037c-13e4-4ced-86db-fb1d88f37083",
    "outputId": "4dafb699-32fa-48bc-a001-147eebc3bb0e",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 82783 images in /Visual-question-answering-model/train2014/\n"
     ]
    }
   ],
   "source": [
    "train_data = CocoImages(pathimg)\n",
    "#    loader = create_coco_loader(pathimg,pathimgval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e53fcda1-2de3-49f4-a320-5652fe7af0a4",
   "metadata": {
    "id": "e53fcda1-2de3-49f4-a320-5652fe7af0a4",
    "outputId": "e7697af2-1f21-4c06-a243-2b50a7f0e0c4",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 82783 images in /Visual-question-answering-model/train2014/\n",
      "found 40504 images in /Visual-question-answering-model/val2014\n"
     ]
    }
   ],
   "source": [
    "pathes = [pathimg,pathimgval]\n",
    "transform = get_transform(config.image_size, config.central_fraction)\n",
    "datasets = [CocoImages(path, transform=transform) for path in pathes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1b940642-987a-4cf4-81ee-cb55a96ddc1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pretrainedmodels\n",
      "  Downloading pretrainedmodels-0.7.4.tar.gz (58 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from pretrainedmodels) (2.0.1)\n",
      "Requirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (from pretrainedmodels) (0.15.2)\n",
      "Collecting munch\n",
      "  Downloading munch-3.0.0-py2.py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from pretrainedmodels) (4.65.0)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from munch->pretrainedmodels) (1.16.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->pretrainedmodels) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch->pretrainedmodels) (4.5.0)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->pretrainedmodels) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->pretrainedmodels) (3.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->pretrainedmodels) (3.1.2)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torchvision->pretrainedmodels) (1.23.5)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from torchvision->pretrainedmodels) (2.29.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision->pretrainedmodels) (9.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->pretrainedmodels) (2.1.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision->pretrainedmodels) (1.26.15)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision->pretrainedmodels) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision->pretrainedmodels) (2023.5.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision->pretrainedmodels) (3.4)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->pretrainedmodels) (1.3.0)\n",
      "Building wheels for collected packages: pretrainedmodels\n",
      "  Building wheel for pretrainedmodels (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pretrainedmodels: filename=pretrainedmodels-0.7.4-py3-none-any.whl size=60945 sha256=9e56b36fb66b1476e1b12ea1baa921ff3a38bba8bca8303d64d4a637b18405f7\n",
      "  Stored in directory: /root/.cache/pip/wheels/35/cb/a5/8f534c60142835bfc889f9a482e4a67e0b817032d9c6883b64\n",
      "Successfully built pretrainedmodels\n",
      "Installing collected packages: munch, pretrainedmodels\n",
      "Successfully installed munch-3.0.0 pretrainedmodels-0.7.4\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install pretrainedmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6WhxrqcokFCp",
   "metadata": {
    "id": "6WhxrqcokFCp",
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"http://data.lip6.fr/cadene/pretrainedmodels/resnext101_32x4d-29e315fa.pth\" to /root/.cache/torch/hub/checkpoints/resnext101_32x4d-29e315fa.pth\n"
     ]
    },
    {
     "ename": "URLError",
     "evalue": "<urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1007)>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mSSLCertVerificationError\u001b[0m                  Traceback (most recent call last)",
      "File \u001b[0;32m/opt/conda/lib/python3.10/urllib/request.py:1348\u001b[0m, in \u001b[0;36mAbstractHTTPHandler.do_open\u001b[0;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[1;32m   1347\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1348\u001b[0m     \u001b[43mh\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselector\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1349\u001b[0m \u001b[43m              \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhas_header\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTransfer-encoding\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1350\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err: \u001b[38;5;66;03m# timeout error\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/http/client.py:1283\u001b[0m, in \u001b[0;36mHTTPConnection.request\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1282\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Send a complete request to the server.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1283\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/http/client.py:1329\u001b[0m, in \u001b[0;36mHTTPConnection._send_request\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1328\u001b[0m     body \u001b[38;5;241m=\u001b[39m _encode(body, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbody\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m-> 1329\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mendheaders\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/http/client.py:1278\u001b[0m, in \u001b[0;36mHTTPConnection.endheaders\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1277\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CannotSendHeader()\n\u001b[0;32m-> 1278\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/http/client.py:1038\u001b[0m, in \u001b[0;36mHTTPConnection._send_output\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1037\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buffer[:]\n\u001b[0;32m-> 1038\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1040\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m message_body \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1041\u001b[0m \n\u001b[1;32m   1042\u001b[0m     \u001b[38;5;66;03m# create a consistent interface to message_body\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/http/client.py:976\u001b[0m, in \u001b[0;36mHTTPConnection.send\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    975\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_open:\n\u001b[0;32m--> 976\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    977\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/http/client.py:1455\u001b[0m, in \u001b[0;36mHTTPSConnection.connect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1453\u001b[0m     server_hostname \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhost\n\u001b[0;32m-> 1455\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrap_socket\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msock\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1456\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserver_hostname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/ssl.py:513\u001b[0m, in \u001b[0;36mSSLContext.wrap_socket\u001b[0;34m(self, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, session)\u001b[0m\n\u001b[1;32m    507\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrap_socket\u001b[39m(\u001b[38;5;28mself\u001b[39m, sock, server_side\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    508\u001b[0m                 do_handshake_on_connect\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    509\u001b[0m                 suppress_ragged_eofs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    510\u001b[0m                 server_hostname\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, session\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    511\u001b[0m     \u001b[38;5;66;03m# SSLSocket class handles server_hostname encoding before it calls\u001b[39;00m\n\u001b[1;32m    512\u001b[0m     \u001b[38;5;66;03m# ctx._wrap_socket()\u001b[39;00m\n\u001b[0;32m--> 513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msslsocket_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    514\u001b[0m \u001b[43m        \u001b[49m\u001b[43msock\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msock\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    515\u001b[0m \u001b[43m        \u001b[49m\u001b[43mserver_side\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserver_side\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    516\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdo_handshake_on_connect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdo_handshake_on_connect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    517\u001b[0m \u001b[43m        \u001b[49m\u001b[43msuppress_ragged_eofs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msuppress_ragged_eofs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    518\u001b[0m \u001b[43m        \u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserver_hostname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    519\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    520\u001b[0m \u001b[43m        \u001b[49m\u001b[43msession\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msession\u001b[49m\n\u001b[1;32m    521\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/ssl.py:1071\u001b[0m, in \u001b[0;36mSSLSocket._create\u001b[0;34m(cls, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, context, session)\u001b[0m\n\u001b[1;32m   1070\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdo_handshake_on_connect should not be specified for non-blocking sockets\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1071\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_handshake\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1072\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mOSError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/ssl.py:1342\u001b[0m, in \u001b[0;36mSSLSocket.do_handshake\u001b[0;34m(self, block)\u001b[0m\n\u001b[1;32m   1341\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msettimeout(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m-> 1342\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_handshake\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1343\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[0;31mSSLCertVerificationError\u001b[0m: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1007)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mURLError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 40\u001b[0m\n\u001b[1;32m     38\u001b[0m cudnn\u001b[38;5;241m.\u001b[39mbenchmark \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CocoImages\n\u001b[0;32m---> 40\u001b[0m net \u001b[38;5;241m=\u001b[39m \u001b[43mNet\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mcuda()\n\u001b[1;32m     41\u001b[0m net\u001b[38;5;241m.\u001b[39meval()\n",
      "Cell \u001b[0;32mIn[37], line 4\u001b[0m, in \u001b[0;36mNet.__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28msuper\u001b[39m(Net, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n\u001b[0;32m----> 4\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[43mpretrainedmodels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresnext101_32x4d\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mimagenet\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Load ResNeXt-101 32x4d model\u001b[39;00m\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msave_output\u001b[39m(module, \u001b[38;5;28minput\u001b[39m, output):\n\u001b[1;32m      7\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuffer \u001b[38;5;241m=\u001b[39m output\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pretrainedmodels/models/resnext.py:85\u001b[0m, in \u001b[0;36mresnext101_32x4d\u001b[0;34m(num_classes, pretrained)\u001b[0m\n\u001b[1;32m     82\u001b[0m settings \u001b[38;5;241m=\u001b[39m pretrained_settings[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresnext101_32x4d\u001b[39m\u001b[38;5;124m'\u001b[39m][pretrained]\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m num_classes \u001b[38;5;241m==\u001b[39m settings[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_classes\u001b[39m\u001b[38;5;124m'\u001b[39m], \\\n\u001b[1;32m     84\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_classes should be \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, but is \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(settings[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_classes\u001b[39m\u001b[38;5;124m'\u001b[39m], num_classes)\n\u001b[0;32m---> 85\u001b[0m model\u001b[38;5;241m.\u001b[39mload_state_dict(\u001b[43mmodel_zoo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_url\u001b[49m\u001b[43m(\u001b[49m\u001b[43msettings\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43murl\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     86\u001b[0m model\u001b[38;5;241m.\u001b[39minput_space \u001b[38;5;241m=\u001b[39m settings[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_space\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     87\u001b[0m model\u001b[38;5;241m.\u001b[39minput_size \u001b[38;5;241m=\u001b[39m settings[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_size\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/hub.py:746\u001b[0m, in \u001b[0;36mload_state_dict_from_url\u001b[0;34m(url, model_dir, map_location, progress, check_hash, file_name)\u001b[0m\n\u001b[1;32m    744\u001b[0m         r \u001b[38;5;241m=\u001b[39m HASH_REGEX\u001b[38;5;241m.\u001b[39msearch(filename)  \u001b[38;5;66;03m# r is Optional[Match[str]]\u001b[39;00m\n\u001b[1;32m    745\u001b[0m         hash_prefix \u001b[38;5;241m=\u001b[39m r\u001b[38;5;241m.\u001b[39mgroup(\u001b[38;5;241m1\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m r \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 746\u001b[0m     \u001b[43mdownload_url_to_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcached_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhash_prefix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprogress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    748\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _is_legacy_zip_format(cached_file):\n\u001b[1;32m    749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _legacy_zip_load(cached_file, model_dir, map_location)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/hub.py:611\u001b[0m, in \u001b[0;36mdownload_url_to_file\u001b[0;34m(url, dst, hash_prefix, progress)\u001b[0m\n\u001b[1;32m    609\u001b[0m file_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    610\u001b[0m req \u001b[38;5;241m=\u001b[39m Request(url, headers\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUser-Agent\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch.hub\u001b[39m\u001b[38;5;124m\"\u001b[39m})\n\u001b[0;32m--> 611\u001b[0m u \u001b[38;5;241m=\u001b[39m \u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    612\u001b[0m meta \u001b[38;5;241m=\u001b[39m u\u001b[38;5;241m.\u001b[39minfo()\n\u001b[1;32m    613\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(meta, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgetheaders\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/urllib/request.py:216\u001b[0m, in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    215\u001b[0m     opener \u001b[38;5;241m=\u001b[39m _opener\n\u001b[0;32m--> 216\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mopener\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/urllib/request.py:525\u001b[0m, in \u001b[0;36mOpenerDirector.open\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    523\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m processor \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_response\u001b[38;5;241m.\u001b[39mget(protocol, []):\n\u001b[1;32m    524\u001b[0m     meth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(processor, meth_name)\n\u001b[0;32m--> 525\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mmeth\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/urllib/request.py:634\u001b[0m, in \u001b[0;36mHTTPErrorProcessor.http_response\u001b[0;34m(self, request, response)\u001b[0m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;66;03m# According to RFC 2616, \"2xx\" code indicates that the client's\u001b[39;00m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;66;03m# request was successfully received, understood, and accepted.\u001b[39;00m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;241m200\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m code \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m300\u001b[39m):\n\u001b[0;32m--> 634\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    635\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhttp\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhdrs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    637\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/urllib/request.py:557\u001b[0m, in \u001b[0;36mOpenerDirector.error\u001b[0;34m(self, proto, *args)\u001b[0m\n\u001b[1;32m    555\u001b[0m     http_err \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    556\u001b[0m args \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mdict\u001b[39m, proto, meth_name) \u001b[38;5;241m+\u001b[39m args\n\u001b[0;32m--> 557\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_chain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    558\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result:\n\u001b[1;32m    559\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/urllib/request.py:496\u001b[0m, in \u001b[0;36mOpenerDirector._call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    494\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m handler \u001b[38;5;129;01min\u001b[39;00m handlers:\n\u001b[1;32m    495\u001b[0m     func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(handler, meth_name)\n\u001b[0;32m--> 496\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    497\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    498\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/urllib/request.py:749\u001b[0m, in \u001b[0;36mHTTPRedirectHandler.http_error_302\u001b[0;34m(self, req, fp, code, msg, headers)\u001b[0m\n\u001b[1;32m    746\u001b[0m fp\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m    747\u001b[0m fp\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m--> 749\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/urllib/request.py:519\u001b[0m, in \u001b[0;36mOpenerDirector.open\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    516\u001b[0m     req \u001b[38;5;241m=\u001b[39m meth(req)\n\u001b[1;32m    518\u001b[0m sys\u001b[38;5;241m.\u001b[39maudit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124murllib.Request\u001b[39m\u001b[38;5;124m'\u001b[39m, req\u001b[38;5;241m.\u001b[39mfull_url, req\u001b[38;5;241m.\u001b[39mdata, req\u001b[38;5;241m.\u001b[39mheaders, req\u001b[38;5;241m.\u001b[39mget_method())\n\u001b[0;32m--> 519\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    521\u001b[0m \u001b[38;5;66;03m# post-process response\u001b[39;00m\n\u001b[1;32m    522\u001b[0m meth_name \u001b[38;5;241m=\u001b[39m protocol\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_response\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/urllib/request.py:536\u001b[0m, in \u001b[0;36mOpenerDirector._open\u001b[0;34m(self, req, data)\u001b[0m\n\u001b[1;32m    533\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[1;32m    535\u001b[0m protocol \u001b[38;5;241m=\u001b[39m req\u001b[38;5;241m.\u001b[39mtype\n\u001b[0;32m--> 536\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_chain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_open\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\n\u001b[1;32m    537\u001b[0m \u001b[43m                          \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m_open\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result:\n\u001b[1;32m    539\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/urllib/request.py:496\u001b[0m, in \u001b[0;36mOpenerDirector._call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    494\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m handler \u001b[38;5;129;01min\u001b[39;00m handlers:\n\u001b[1;32m    495\u001b[0m     func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(handler, meth_name)\n\u001b[0;32m--> 496\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    497\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    498\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/urllib/request.py:1391\u001b[0m, in \u001b[0;36mHTTPSHandler.https_open\u001b[0;34m(self, req)\u001b[0m\n\u001b[1;32m   1390\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhttps_open\u001b[39m(\u001b[38;5;28mself\u001b[39m, req):\n\u001b[0;32m-> 1391\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhttp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mHTTPSConnection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1392\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_context\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_hostname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_hostname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/urllib/request.py:1351\u001b[0m, in \u001b[0;36mAbstractHTTPHandler.do_open\u001b[0;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[1;32m   1348\u001b[0m         h\u001b[38;5;241m.\u001b[39mrequest(req\u001b[38;5;241m.\u001b[39mget_method(), req\u001b[38;5;241m.\u001b[39mselector, req\u001b[38;5;241m.\u001b[39mdata, headers,\n\u001b[1;32m   1349\u001b[0m                   encode_chunked\u001b[38;5;241m=\u001b[39mreq\u001b[38;5;241m.\u001b[39mhas_header(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTransfer-encoding\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m   1350\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err: \u001b[38;5;66;03m# timeout error\u001b[39;00m\n\u001b[0;32m-> 1351\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m URLError(err)\n\u001b[1;32m   1352\u001b[0m     r \u001b[38;5;241m=\u001b[39m h\u001b[38;5;241m.\u001b[39mgetresponse()\n\u001b[1;32m   1353\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n",
      "\u001b[0;31mURLError\u001b[0m: <urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1007)>"
     ]
    }
   ],
   "source": [
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.model = pretrainedmodels.resnext101_32x4d(pretrained='imagenet')  # Load ResNeXt-101 32x4d model\n",
    "\n",
    "        def save_output(module, input, output):\n",
    "            self.buffer = output\n",
    "        self.model.layer4.register_forward_hook(save_output)\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.model(x)\n",
    "        return self.buffer32x4d(pretrained='imagenet')  # Load ResNeXt-101 32x4d model\n",
    "\n",
    "        def save_output(module, input, output):\n",
    "            self.buffer = output\n",
    "\n",
    "        self.model.layer4.register_forward_hook(save_output)\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.model(x)\n",
    "        return self.buffer\n",
    "\n",
    "\n",
    "\n",
    "def create_coco_loader(*paths):\n",
    "    transform = utils.get_transform(config.image_size, config.central_fraction)\n",
    "    datasets = [data.CocoImages(path, transform=transform) for path in paths]\n",
    "    dataset = data.Composite(*datasets)\n",
    "    data_loader = torch.utils.data.DataLoader(\n",
    "        dataset,\n",
    "        batch_size=config.preprocess_batch_size,\n",
    "        num_workers=config.data_workers,\n",
    "        shuffle=False,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "    return data_loader\n",
    "\n",
    "cudnn.benchmark = True\n",
    "from data import CocoImages\n",
    "net = Net().cuda()\n",
    "net.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c8281f-87d2-4c73-8506-7f8b27e429ad",
   "metadata": {
    "id": "09c8281f-87d2-4c73-8506-7f8b27e429ad",
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = Composite(*datasets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f05dbb7-22f9-477d-b332-8f8751e3df3e",
   "metadata": {
    "id": "0f05dbb7-22f9-477d-b332-8f8751e3df3e",
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_loader = torch.utils.data.DataLoader(\n",
    "        dataset,\n",
    "        batch_size=config.preprocess_batch_size,\n",
    "        num_workers=config.data_workers,\n",
    "        shuffle=False,\n",
    "        pin_memory=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c45998c-ae75-4148-a21b-e91ef3d290b7",
   "metadata": {
    "id": "4c45998c-ae75-4148-a21b-e91ef3d290b7",
    "tags": []
   },
   "outputs": [],
   "source": [
    "loader = data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tH7yme3EMMVT",
   "metadata": {
    "id": "tH7yme3EMMVT",
    "outputId": "a85d719e-bc76-40cb-f572-ce0eec0cb3ae",
    "tags": []
   },
   "outputs": [],
   "source": [
    "features_shape = (\n",
    "  len(loader.dataset),\n",
    "  2560,\n",
    "  config.output_size,\n",
    "  config.output_size\n",
    ")\n",
    "import numpy as np\n",
    "\n",
    "with h5py.File(config.preprocessed_path, 'w', libver='latest') as fd:\n",
    "    features = fd.create_dataset('features', shape=features_shape, dtype='float16')\n",
    "    coco_ids = fd.create_dataset('ids', shape=(len(loader.dataset),), dtype='int32')\n",
    "\n",
    "    i = j = 0\n",
    "    for ids, imgs in tqdm(loader):\n",
    "        with torch.no_grad():\n",
    "            imgs = Variable(imgs.cuda(), volatile=True)\n",
    "            out = net(imgs)\n",
    "\n",
    "            j = i + imgs.size(0)\n",
    "            reshaped_features = out.data.cpu().numpy().astype('float16')\n",
    "            reshaped_features = reshaped_features.reshape(j - i, 2560, 1, 1)\n",
    "            features[i:j, :, :, :] = np.tile(reshaped_features, (1, 1, config.output_size, config.output_size))\n",
    "            coco_ids[i:j] = ids.numpy().astype('int32')\n",
    "            i = j\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38535874",
   "metadata": {
    "id": "38535874",
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "571bf54a",
   "metadata": {
    "id": "571bf54a",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Pre-process vocabularies for questions and answers from VQA 2.0 Abstract Scene: https://visualqa.org/vqa_v1_download.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "KlH1qztYsq0g",
   "metadata": {
    "id": "KlH1qztYsq0g",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_vocab(iterable, top_k=None, start=0):\n",
    "    \"\"\" Turns an iterable of list of tokens into a vocabulary.\n",
    "        These tokens could be single answers or word tokens in questions.\n",
    "    \"\"\"\n",
    "    all_tokens = itertools.chain.from_iterable(iterable)\n",
    "    counter = Counter(all_tokens)\n",
    "    if top_k:\n",
    "        most_common = counter.most_common(top_k)\n",
    "        most_common = (t for t, c in most_common)\n",
    "    else:\n",
    "        most_common = counter.keys()\n",
    "    # descending in count, then lexicographical order\n",
    "    tokens = sorted(most_common, key=lambda x: (counter[x], x), reverse=True)\n",
    "    vocab = {t: i for i, t in enumerate(tokens, start=start)}\n",
    "    return vocab\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "eb8d8880-bc1e-42e5-81bf-0964d2a428d2",
   "metadata": {
    "id": "eb8d8880-bc1e-42e5-81bf-0964d2a428d2",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def path_for(train=False, val=False, test=False, question=False,answer =False):\n",
    "    assert train + val + test == 1\n",
    "    assert question + answer == 1\n",
    "    assert not (test and answer), 'loading answers from test split not supported'  # if you want to eval on test, you need to implement loading of a VQA Dataset without given answers yourself\n",
    "    if val and question:\n",
    "        fmt = 'v2_OpenEnded_mscoco_val2014_questions.json'\n",
    "    elif val and answer:\n",
    "        fmt = 'v2_mscoco_val2014_annotations.json'\n",
    "    elif answer and train:\n",
    "        fmt = 'v2_mscoco_train2014_annotations.json'\n",
    "    elif question and train:\n",
    "        fmt = 'v2_OpenEnded_mscoco_train2014_questions.json'\n",
    "    else:\n",
    "        fmt = '{1}_{2}_annotations.json'\n",
    "    s = fmt\n",
    "    qa_path = '/Visual-question-answering-model'  # directory containing the question and annotation jsons\n",
    "    return os.path.join(qa_path, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9Jg17j2lsq_K",
   "metadata": {
    "id": "9Jg17j2lsq_K",
    "tags": []
   },
   "outputs": [],
   "source": [
    "    questions = path_for(train=True, question=True)\n",
    "    answers = path_for(train=True, answer=True)\n",
    "    with open(questions, 'r') as fd:\n",
    "        questions = json.load(fd)\n",
    "    with open(answers, 'r') as fd:\n",
    "        answers = json.load(fd)\n",
    "\n",
    "    questions = prepare_questions(questions)\n",
    "    answers = prepare_answers(answers)\n",
    "\n",
    "    question_vocab = extract_vocab(questions, start=1)\n",
    "    answer_vocab = extract_vocab(answers, top_k=config.max_answers)\n",
    "\n",
    "    vocabs = {\n",
    "        'question': question_vocab,\n",
    "        'answer': answer_vocab,\n",
    "    }\n",
    "    with open(config.vocabulary_path, 'w') as fd:\n",
    "        json.dump(vocabs, fd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "G3K6c4pFsrB2",
   "metadata": {
    "id": "G3K6c4pFsrB2"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "UymeElGGsrEk",
   "metadata": {
    "id": "UymeElGGsrEk"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836bb335",
   "metadata": {
    "id": "836bb335"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b8e2b3",
   "metadata": {
    "id": "91b8e2b3",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Now start training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "uc7W9tW-s7X4",
   "metadata": {
    "id": "uc7W9tW-s7X4",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def update_learning_rate(optimizer, iteration):\n",
    "    lr = config.initial_lr * 0.5**(float(iteration) / config.lr_halflife)\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "\n",
    "\n",
    "total_iterations = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c0d0d6df-cea8-4fb3-9b6c-cba8d933d130",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import torch.nn.init as init\n",
    "from torch.nn.utils.rnn import pack_padded_sequence\n",
    "\n",
    "import config\n",
    "\n",
    "\n",
    "class model7(nn.Module):\n",
    "    \"\"\" Re-implementation of ``Show, Ask, Attend, and Answer: A Strong Baseline For Visual Question Answering'' [0]\n",
    "\n",
    "    [0]: https://arxiv.org/abs/1704.03162\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, embedding_tokens):\n",
    "        super(model7, self).__init__()\n",
    "        question_features = 1024\n",
    "        vision_features =2560\n",
    "        glimpses = 2\n",
    "\n",
    "        self.text = TextProcessor(\n",
    "            embedding_tokens=embedding_tokens,\n",
    "            embedding_features=500,\n",
    "            lstm_features=question_features,\n",
    "            drop=0.5,\n",
    "        )\n",
    "        self.attention = Attention(\n",
    "            v_features=vision_features,\n",
    "            q_features=question_features,\n",
    "            mid_features=512,\n",
    "            glimpses=2,\n",
    "            drop=0.5,\n",
    "        )\n",
    "        self.classifier = Classifier(\n",
    "            in_features=glimpses * vision_features + question_features,\n",
    "            mid_features=1024,\n",
    "            out_features=config.max_answers,\n",
    "            drop=0.5,\n",
    "        )\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear) or isinstance(m, nn.Conv2d):\n",
    "                init.xavier_uniform(m.weight)\n",
    "                if m.bias is not None:\n",
    "                    m.bias.data.zero_()\n",
    "\n",
    "    def forward(self, v, q, q_len):\n",
    "        q = self.text(q, list(q_len.data))\n",
    "\n",
    "        v = v / (v.norm(p=2, dim=1, keepdim=True).expand_as(v) + 1e-8)\n",
    "        a = self.attention(v, q)\n",
    "        v = apply_attention(v, a)\n",
    "\n",
    "        combined = torch.cat([v, q], dim=1)\n",
    "        answer = self.classifier(combined)\n",
    "        return answer, a\n",
    "\n",
    "\n",
    "class Classifier(nn.Sequential):\n",
    "    def __init__(self, in_features, mid_features, out_features, drop=0.0):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.add_module('drop1', nn.Dropout(drop))\n",
    "        self.add_module('lin1', nn.Linear(in_features, mid_features))\n",
    "        self.add_module('relu', nn.ReLU())\n",
    "        self.add_module('drop2', nn.Dropout(drop))\n",
    "        self.add_module('lin2', nn.Linear(mid_features, out_features))\n",
    "\n",
    "\n",
    "class TextProcessor(nn.Module):\n",
    "    def __init__(self, embedding_tokens, embedding_features, lstm_features, drop=0.0):\n",
    "        super(TextProcessor, self).__init__()\n",
    "        self.embedding = nn.Embedding(embedding_tokens, embedding_features, padding_idx=0)\n",
    "        self.drop = nn.Dropout(drop)\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.lstm = nn.LSTM(input_size=embedding_features,\n",
    "                            hidden_size=lstm_features,\n",
    "                            num_layers=1)\n",
    "        self.features = lstm_features\n",
    "\n",
    "        self._init_lstm(self.lstm.weight_ih_l0)\n",
    "        self._init_lstm(self.lstm.weight_hh_l0)\n",
    "        self.lstm.bias_ih_l0.data.zero_()\n",
    "        self.lstm.bias_hh_l0.data.zero_()\n",
    "\n",
    "        init.xavier_uniform(self.embedding.weight)\n",
    "\n",
    "    def _init_lstm(self, weight):\n",
    "        for w in weight.chunk(4, 0):\n",
    "            init.xavier_uniform_(w)\n",
    "\n",
    "    def forward(self, q, q_len):\n",
    "        embedded = self.embedding(q)\n",
    "        tanhed = self.tanh(self.drop(embedded))\n",
    "        packed = pack_padded_sequence(tanhed, q_len, batch_first=True)\n",
    "        _, (_, c) = self.lstm(packed)\n",
    "        return c.squeeze(0)\n",
    "\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, v_features, q_features, mid_features, glimpses, drop=0.0):\n",
    "        super(Attention, self).__init__()\n",
    "        self.v_conv = nn.Conv2d(v_features, mid_features, 1, bias=False)  # let self.lin take care of bias\n",
    "        self.q_lin = nn.Linear(q_features, mid_features)\n",
    "        self.x_conv = nn.Conv2d(mid_features, glimpses, 1)\n",
    "\n",
    "        self.drop = nn.Dropout(drop)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, v, q):\n",
    "        v = self.v_conv(self.drop(v))\n",
    "        q = self.q_lin(self.drop(q))\n",
    "        q = tile_2d_over_nd(q, v)\n",
    "        x = self.relu(v + q)\n",
    "        x = self.x_conv(self.drop(x))\n",
    "        return x\n",
    "\n",
    "\n",
    "def apply_attention(input, attention):\n",
    "    \"\"\" Apply any number of attention maps over the input. \"\"\"\n",
    "    n, c = input.size()[:2]\n",
    "    glimpses = attention.size(1)\n",
    "\n",
    "    # flatten the spatial dims into the third dim, since we don't need to care about how they are arranged\n",
    "    input = input.view(n, 1, c, -1) # [n, 1, c, s]\n",
    "    attention = attention.view(n, glimpses, -1)\n",
    "    attention = F.softmax(attention, dim=-1).unsqueeze(2) # [n, g, 1, s]\n",
    "    weighted = attention * input # [n, g, v, s]\n",
    "    weighted_mean = weighted.sum(dim=-1) # [n, g, v]\n",
    "    return weighted_mean.view(n, -1)\n",
    "\n",
    "\n",
    "def tile_2d_over_nd(feature_vector, feature_map):\n",
    "    \"\"\" Repeat the same feature vector over all spatial positions of a given feature map.\n",
    "        The feature vector should have the same batch size and number of features as the feature map.\n",
    "    \"\"\"\n",
    "    n, c = feature_vector.size()\n",
    "    spatial_size = feature_map.dim() - 2\n",
    "    tiled = feature_vector.view(n, c, *([1] * spatial_size)).expand_as(feature_map)\n",
    "    return tiled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "IHmrUH3GtDuA",
   "metadata": {
    "id": "IHmrUH3GtDuA",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run(net, loader, optimizer, tracker, train=False, prefix='', epoch=0):\n",
    "    \"\"\" Run an epoch over the given loader \"\"\"\n",
    "    if train:\n",
    "        net.train()\n",
    "        tracker_class, tracker_params = tracker.MovingMeanMonitor, {'momentum': 0.99}\n",
    "    else:\n",
    "        net.eval()\n",
    "        tracker_class, tracker_params = tracker.MeanMonitor, {}\n",
    "        answ = []\n",
    "        idxs = []\n",
    "        accs = []\n",
    "\n",
    "    tq = tqdm(loader, desc='{} E{:03d}'.format(prefix, epoch), ncols=0)\n",
    "    loss_tracker = tracker.track('{}_loss'.format(prefix), tracker_class(**tracker_params))\n",
    "    acc_tracker = tracker.track('{}_acc'.format(prefix), tracker_class(**tracker_params))\n",
    "\n",
    "    log_softmax = nn.LogSoftmax().cuda()\n",
    "    for v, q, a, idx, q_len in tq:\n",
    "        var_params = {\n",
    "            'volatile': not train,\n",
    "            'requires_grad': False,\n",
    "        }\n",
    "        v = Variable(v.cuda(), **var_params)\n",
    "        q = Variable(q.cuda(), **var_params)\n",
    "        a = Variable(a.cuda(), **var_params)\n",
    "        q_len = Variable(q_len.cuda(), **var_params)\n",
    "\n",
    "        out,_ = net(v, q, q_len)\n",
    "        nll = -log_softmax(out)\n",
    "        loss = (nll * a / 10).sum(dim=1).mean()\n",
    "        acc = utils.batch_accuracy(out.data, a.data).cpu()\n",
    "\n",
    "        if train:\n",
    "            global total_iterations\n",
    "            update_learning_rate(optimizer, total_iterations)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_iterations += 1\n",
    "        else:\n",
    "            # store information about evaluation of this minibatch\n",
    "            _, answer = out.data.cpu().max(dim=1)\n",
    "            answ.append(answer.view(-1))\n",
    "            accs.append(acc.view(-1))\n",
    "            idxs.append(idx.view(-1).clone())\n",
    "\n",
    "        loss_tracker.append(loss.item())\n",
    "        # acc_tracker.append(acc.mean())\n",
    "        for a in acc:\n",
    "            acc_tracker.append(a.item())\n",
    "        fmt = '{:.4f}'.format\n",
    "        tq.set_postfix(loss=fmt(loss_tracker.mean.value), acc=fmt(acc_tracker.mean.value))\n",
    "\n",
    "    if not train:\n",
    "        answ = list(torch.cat(answ, dim=0))\n",
    "        accs = list(torch.cat(accs, dim=0))\n",
    "        idxs = list(torch.cat(idxs, dim=0))\n",
    "        return answ, accs, idxs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "mjkcRqpKtEZq",
   "metadata": {
    "id": "mjkcRqpKtEZq",
    "outputId": "27f14849-1fba-4f41-f8d0-de0c7a55e7df",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "will save to logs/model7.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4706/3926530035.py:84: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
      "  init.xavier_uniform(self.embedding.weight)\n",
      "/tmp/ipykernel_4706/3926530035.py:42: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
      "  init.xavier_uniform(m.weight)\n",
      "train E000:   0% 0/3396 [00:00<?, ?it/s]/tmp/ipykernel_4706/1024819654.py:29: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  nll = -log_softmax(out)\n",
      "train E000: 100% 3396/3396 [09:00<00:00,  6.28it/s, acc=0.4106, loss=1.9751]\n",
      "val E000:   0% 0/1675 [00:00<?, ?it/s]/tmp/ipykernel_4706/1024819654.py:23: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  v = Variable(v.cuda(), **var_params)\n",
      "/tmp/ipykernel_4706/1024819654.py:24: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  q = Variable(q.cuda(), **var_params)\n",
      "/tmp/ipykernel_4706/1024819654.py:25: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  a = Variable(a.cuda(), **var_params)\n",
      "/tmp/ipykernel_4706/1024819654.py:26: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  q_len = Variable(q_len.cuda(), **var_params)\n",
      "val E000: 100% 1675/1675 [04:46<00:00,  5.85it/s, acc=0.4703, loss=1.8172]\n",
      "train E001: 100% 3396/3396 [08:16<00:00,  6.84it/s, acc=0.5415, loss=1.8155]\n",
      "val E001: 100% 1675/1675 [04:29<00:00,  6.21it/s, acc=0.4993, loss=1.7047]\n",
      "train E002: 100% 3396/3396 [09:01<00:00,  6.27it/s, acc=0.5140, loss=1.7310]\n",
      "val E002: 100% 1675/1675 [04:39<00:00,  6.00it/s, acc=0.4997, loss=1.6699]\n",
      "train E003: 100% 3396/3396 [08:40<00:00,  6.53it/s, acc=0.5349, loss=1.6766]\n",
      "val E003: 100% 1675/1675 [04:28<00:00,  6.25it/s, acc=0.5186, loss=1.6381]\n",
      "train E004: 100% 3396/3396 [09:10<00:00,  6.17it/s, acc=0.5455, loss=1.6380]\n",
      "val E004: 100% 1675/1675 [04:31<00:00,  6.17it/s, acc=0.5257, loss=1.6249]\n",
      "train E005: 100% 3396/3396 [09:13<00:00,  6.13it/s, acc=0.5767, loss=1.5941]\n",
      "val E005: 100% 1675/1675 [04:29<00:00,  6.22it/s, acc=0.5299, loss=1.6155]\n",
      "train E006: 100% 3396/3396 [09:04<00:00,  6.24it/s, acc=0.5370, loss=1.5720]\n",
      "val E006: 100% 1675/1675 [04:26<00:00,  6.28it/s, acc=0.5325, loss=1.6076]\n",
      "train E007: 100% 3396/3396 [08:45<00:00,  6.47it/s, acc=0.6050, loss=1.5396]\n",
      "val E007: 100% 1675/1675 [04:33<00:00,  6.13it/s, acc=0.5357, loss=1.6044]\n",
      "train E008: 100% 3396/3396 [09:10<00:00,  6.16it/s, acc=0.5248, loss=1.5114]\n",
      "val E008: 100% 1675/1675 [04:45<00:00,  5.86it/s, acc=0.5378, loss=1.6030]\n",
      "train E009: 100% 3396/3396 [08:57<00:00,  6.31it/s, acc=0.6333, loss=1.5038]\n",
      "val E009: 100% 1675/1675 [04:34<00:00,  6.10it/s, acc=0.5395, loss=1.6008]\n",
      "train E010: 100% 3396/3396 [09:01<00:00,  6.27it/s, acc=0.5880, loss=1.4867]\n",
      "val E010: 100% 1675/1675 [04:40<00:00,  5.98it/s, acc=0.5423, loss=1.5983]\n",
      "train E011: 100% 3396/3396 [08:47<00:00,  6.44it/s, acc=0.5674, loss=1.4716]\n",
      "val E011: 100% 1675/1675 [04:25<00:00,  6.32it/s, acc=0.5426, loss=1.5969]\n",
      "train E012: 100% 3396/3396 [09:02<00:00,  6.26it/s, acc=0.5229, loss=1.4648]\n",
      "val E012: 100% 1675/1675 [04:28<00:00,  6.23it/s, acc=0.5453, loss=1.5971]\n",
      "train E013: 100% 3396/3396 [09:21<00:00,  6.04it/s, acc=0.4568, loss=2.0330]\n",
      "val E013:   0% 0/1675 [00:04<?, ?it/s]\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "Caught OSError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/worker.py\", line 308, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py\", line 51, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py\", line 51, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/tmp/ipykernel_4706/3112702561.py\", line 160, in __getitem__\n    v = self._load_image(image_id)\n  File \"/tmp/ipykernel_4706/3112702561.py\", line 146, in _load_image\n    self.features_file = h5py.File(self.image_features_path, 'r')\n  File \"/opt/conda/lib/python3.10/site-packages/h5py/_hl/files.py\", line 567, in __init__\n    fid = make_fid(name, mode, userblock_size, fapl, fcpl, swmr=swmr)\n  File \"/opt/conda/lib/python3.10/site-packages/h5py/_hl/files.py\", line 231, in make_fid\n    fid = h5f.open(name, flags, fapl=fapl)\n  File \"h5py/_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper\n  File \"h5py/_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper\n  File \"h5py/h5f.pyx\", line 106, in h5py.h5f.open\nOSError: Unable to open file (file signature not found)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[51], line 25\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(config\u001b[38;5;241m.\u001b[39mepochs):\n\u001b[1;32m     24\u001b[0m     _ \u001b[38;5;241m=\u001b[39m run(net, train_loader, optimizer, tracker, train\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, prefix\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m, epoch\u001b[38;5;241m=\u001b[39mi)\n\u001b[0;32m---> 25\u001b[0m     r \u001b[38;5;241m=\u001b[39m \u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtracker\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mval\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m     results \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m: name,\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtracker\u001b[39m\u001b[38;5;124m'\u001b[39m: tracker\u001b[38;5;241m.\u001b[39mto_dict(),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvocab\u001b[39m\u001b[38;5;124m'\u001b[39m: train_loader\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39mvocab,\n\u001b[1;32m     38\u001b[0m }\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;66;03m# Create the parent directory if it doesn't exist\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[50], line 18\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(net, loader, optimizer, tracker, train, prefix, epoch)\u001b[0m\n\u001b[1;32m     15\u001b[0m acc_tracker \u001b[38;5;241m=\u001b[39m tracker\u001b[38;5;241m.\u001b[39mtrack(\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m_acc\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(prefix), tracker_class(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mtracker_params))\n\u001b[1;32m     17\u001b[0m log_softmax \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mLogSoftmax()\u001b[38;5;241m.\u001b[39mcuda()\n\u001b[0;32m---> 18\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m v, q, a, idx, q_len \u001b[38;5;129;01min\u001b[39;00m tq:\n\u001b[1;32m     19\u001b[0m     var_params \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     20\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvolatile\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;129;01mnot\u001b[39;00m train,\n\u001b[1;32m     21\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrequires_grad\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     22\u001b[0m     }\n\u001b[1;32m     23\u001b[0m     v \u001b[38;5;241m=\u001b[39m Variable(v\u001b[38;5;241m.\u001b[39mcuda(), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mvar_params)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tqdm/std.py:1178\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1175\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1177\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1178\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m   1179\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m   1180\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1181\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:633\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    631\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    632\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 633\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    634\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    635\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    636\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    637\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1345\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1343\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1344\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_task_info[idx]\n\u001b[0;32m-> 1345\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1371\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1369\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_try_put_index()\n\u001b[1;32m   1370\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ExceptionWrapper):\n\u001b[0;32m-> 1371\u001b[0m     \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1372\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_utils.py:644\u001b[0m, in \u001b[0;36mExceptionWrapper.reraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    640\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    641\u001b[0m     \u001b[38;5;66;03m# If the exception takes multiple arguments, don't try to\u001b[39;00m\n\u001b[1;32m    642\u001b[0m     \u001b[38;5;66;03m# instantiate since we don't know how to\u001b[39;00m\n\u001b[1;32m    643\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 644\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception\n",
      "\u001b[0;31mOSError\u001b[0m: Caught OSError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/worker.py\", line 308, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py\", line 51, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py\", line 51, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/tmp/ipykernel_4706/3112702561.py\", line 160, in __getitem__\n    v = self._load_image(image_id)\n  File \"/tmp/ipykernel_4706/3112702561.py\", line 146, in _load_image\n    self.features_file = h5py.File(self.image_features_path, 'r')\n  File \"/opt/conda/lib/python3.10/site-packages/h5py/_hl/files.py\", line 567, in __init__\n    fid = make_fid(name, mode, userblock_size, fapl, fcpl, swmr=swmr)\n  File \"/opt/conda/lib/python3.10/site-packages/h5py/_hl/files.py\", line 231, in make_fid\n    fid = h5f.open(name, flags, fapl=fapl)\n  File \"h5py/_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper\n  File \"h5py/_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper\n  File \"h5py/h5f.pyx\", line 106, in h5py.h5f.open\nOSError: Unable to open file (file signature not found)\n"
     ]
    }
   ],
   "source": [
    "    import torch.optim as optim\n",
    "    from torch.autograd import Variable\n",
    "    import torch.backends.cudnn as cudnn\n",
    "    from tqdm import tqdm\n",
    "    from datetime import datetime\n",
    "    \n",
    "    from datetime import datetime\n",
    "    name = datetime.now().strftime(\"model7\")\n",
    "    target_name = os.path.join('logs', '{}.pth'.format(name))\n",
    "    print('will save to {}'.format(target_name))\n",
    "\n",
    "    cudnn.benchmark = True\n",
    "\n",
    "    train_loader = get_loader(train=True)\n",
    "    val_loader = get_loader(val=True)\n",
    "\n",
    "    net = model7(train_loader.dataset.num_tokens).cuda()\n",
    "    optimizer = optim.Adam([p for p in net.parameters() if p.requires_grad])\n",
    "\n",
    "    tracker = utils.Tracker()\n",
    "    config_as_dict = {k: v for k, v in vars(config).items() if not k.startswith('__')}\n",
    "\n",
    "    for i in range(config.epochs):\n",
    "        _ = run(net, train_loader, optimizer, tracker, train=True, prefix='train', epoch=i)\n",
    "        r = run(net, val_loader, optimizer, tracker, train=False, prefix='val', epoch=i)\n",
    "\n",
    "        results = {\n",
    "        'name': name,\n",
    "        'tracker': tracker.to_dict(),\n",
    "        'config': config_as_dict,\n",
    "        'weights': net.state_dict(),\n",
    "        'eval': {\n",
    "            'answers': r[0],\n",
    "            'accuracies': r[1],\n",
    "            'idx': r[2],\n",
    "        },\n",
    "        'vocab': train_loader.dataset.vocab,\n",
    "    }\n",
    "        # Create the parent directory if it doesn't exist\n",
    "        os.makedirs('logs', exist_ok=True)\n",
    "        torch.save(results, target_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b6df82",
   "metadata": {
    "id": "02b6df82",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot diagram based on training result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ZZkeUiw3tjyu",
   "metadata": {
    "id": "ZZkeUiw3tjyu",
    "outputId": "e2e0e6a8-7c64-4129-e01b-470f5b10d43c",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "path =\"/Visual-question-answering-model/logs/model7.pth\"\n",
    "results = torch.load(path)\n",
    "val_acc = torch.FloatTensor(results['tracker']['val_acc'])\n",
    "val_acc = val_acc.mean(dim=1).numpy()\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure()\n",
    "plt.plot(val_acc)\n",
    "plt.savefig('val_acc.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "84b33a7f",
   "metadata": {
    "id": "84b33a7f",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def prepare_questions(questions):\n",
    "    '''\n",
    "    Remove punctuation marks and spaces. Returns list\n",
    "    '''\n",
    "    questions = [questions]\n",
    "    for question in questions:\n",
    "        question = question.lower()[:-1]\n",
    "        yield question.split(' ')\n",
    "\n",
    "def encode_question(question):\n",
    "    '''\n",
    "    Encode questions\n",
    "    Get ids using vocabulary created using tokens during training\n",
    "    '''\n",
    "    vec = torch.zeros(len(question)).long()\n",
    "    with open(config.vocabulary_path, 'r') as fd:\n",
    "        vocab_json = json.load(fd)\n",
    "    token_to_index = vocab_json['question']\n",
    "    for i, token in enumerate(question):\n",
    "        index = token_to_index.get(token, 0)\n",
    "        vec[i] = index\n",
    "    return vec, len(question)\n",
    "\n",
    "def encode_img(net,img_path):\n",
    "    '''\n",
    "    Encoding input image using Resnet features. Resizes input image to config.image_size\n",
    "    '''\n",
    "    cudnn.benchmark = True\n",
    "    transform = get_transform(config.image_size, config.central_fraction)\n",
    "    img = Image.open(img_path).convert('RGB')\n",
    "    img = transform(img)\n",
    "    ix,iy = img.size()[1],img.size()[2]\n",
    "    net = Net().cuda()\n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        img = Variable(img.cuda())\n",
    "        out = net(img.view(1,3,ix,iy))\n",
    "        features = out.data.cpu().numpy().astype('float32')\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0cc32078-4bbf-4b25-93c5-9fcb2654a780",
   "metadata": {
    "id": "0cc32078-4bbf-4b25-93c5-9fcb2654a780",
    "outputId": "b15a61ed-68cb-4412-affe-f421339e6f9f",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-image in /opt/conda/lib/python3.10/site-packages (0.20.0)\n",
      "Requirement already satisfied: pillow>=9.0.1 in /opt/conda/lib/python3.10/site-packages (from scikit-image) (9.4.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from scikit-image) (23.0)\n",
      "Requirement already satisfied: networkx>=2.8 in /opt/conda/lib/python3.10/site-packages (from scikit-image) (3.1)\n",
      "Requirement already satisfied: numpy>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from scikit-image) (1.23.5)\n",
      "Requirement already satisfied: imageio>=2.4.1 in /opt/conda/lib/python3.10/site-packages (from scikit-image) (2.28.1)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in /opt/conda/lib/python3.10/site-packages (from scikit-image) (2023.4.12)\n",
      "Requirement already satisfied: scipy>=1.8 in /opt/conda/lib/python3.10/site-packages (from scikit-image) (1.10.1)\n",
      "Requirement already satisfied: lazy_loader>=0.1 in /opt/conda/lib/python3.10/site-packages (from scikit-image) (0.2)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-image) (1.4.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade scikit-image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2485dccb",
   "metadata": {
    "id": "2485dccb",
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage\n",
    "import torch\n",
    "import model\n",
    "\n",
    "def demo(img_path,question):\n",
    "    '''\n",
    "    Main demo function. Takes input image path and Question string as input\n",
    "    Returns top 5 answers, shows input image and visualizes attention applied \n",
    "    '''\n",
    "    print('The Question asked was: ',question)\n",
    "    cudnn.benchmark = True\n",
    "    # Load pre-trained image\n",
    "    log = torch.load('/Visual-question-answering-model/logs/model7.pth')\n",
    "    tokens = len(log['vocab']['question']) + 1\n",
    "    net = model7(tokens).cpu()\n",
    "    net.load_state_dict(log['weights'])\n",
    "    net.eval()\n",
    "    \n",
    "    questions = list(prepare_questions(question))\n",
    "    questions = [encode_question(q) for q in questions]\n",
    "    q,q_len = questions[0]\n",
    "    q = q.unsqueeze(0)\n",
    "\n",
    "    v = encode_img(net,img_path)\n",
    "    v = torch.from_numpy(v).to(torch.float)\n",
    "    q_len = torch.tensor([q_len])\n",
    "    with torch.no_grad():\n",
    "        v = Variable(v)\n",
    "        q = Variable(q)\n",
    "        q_len = Variable(q_len)  \n",
    "    \n",
    "    out,att_out = net.forward(v,q,q_len)\n",
    "    out = out.data.cpu()\n",
    "    _, answer5 = torch.topk(out,5)\n",
    "    answers = []\n",
    "    with open(config.vocabulary_path, 'r') as fd:\n",
    "        vocab_json = json.load(fd)\n",
    "    a_to_i = vocab_json['answer']\n",
    "    for answer in answer5:\n",
    "        answer = (answer.view(-1))\n",
    "        for a in answer.data:\n",
    "            answers.append(list(a_to_i.keys())[a.data])        \n",
    "    print_answers(answers)\n",
    "    visualize_attentn(att_out,img_path)\n",
    "    return\n",
    "\n",
    "def visualize_attentn(att_out,img_path):\n",
    "    '''\n",
    "    Takes output of attention layer and overlays on input image. Then shows both \n",
    "    '''\n",
    "    att_out = att_out.view(-1,14,14)\n",
    "    num_im = att_out.size()[0]\n",
    "    im = Image.open(img_path)\n",
    "    fig2,ax2 = plt.subplots(1)\n",
    "    ax2.imshow(im)\n",
    "    ax2.set_title('Original Image')\n",
    "    ax2.axis('off')\n",
    "    fig,axs = plt.subplots(1,num_im,figsize=(10,10))\n",
    "    axs = axs.ravel()\n",
    "    for i in range(0,num_im):\n",
    "        a1 = att_out[i].cpu().detach()\n",
    "        a1 = a1.numpy()\n",
    "        a1 = skimage.transform.pyramid_expand(a1, upscale=64)\n",
    "        im = im.resize(a1.shape)\n",
    "        axs[i].imshow(im)\n",
    "        axs[i].imshow(a1,cmap='gray',alpha=0.65)\n",
    "        axs[i].set_title('Attention image '+str(i))\n",
    "    for ax in axs:\n",
    "        ax.axis('off')\n",
    "    return\n",
    "\n",
    "def print_answers(answers):\n",
    "    '''\n",
    "    Function to print top 5 answers\n",
    "    '''\n",
    "    for i,a in enumerate(answers):\n",
    "        print(\"The top \",i+1,\" answer is \",a)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a4bec047-7018-4d9f-95b1-414e25481fd7",
   "metadata": {
    "id": "a4bec047-7018-4d9f-95b1-414e25481fd7",
    "outputId": "ab9e3893-4f61-4a36-9d84-dc731efb97da",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Question asked was:  What race is the man in the front with glasses?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4706/3926530035.py:84: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
      "  init.xavier_uniform(self.embedding.weight)\n",
      "/tmp/ipykernel_4706/3926530035.py:42: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
      "  init.xavier_uniform(m.weight)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b7\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected 3D (unbatched) or 4D (batched) input to conv2d, but got input of size: [1, 2560]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[63], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdemo\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mCOCO_val2014_000000001436.jpg\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mWhat race is the man in the front with glasses?\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[59], line 34\u001b[0m, in \u001b[0;36mdemo\u001b[0;34m(img_path, question)\u001b[0m\n\u001b[1;32m     31\u001b[0m     q \u001b[38;5;241m=\u001b[39m Variable(q)\n\u001b[1;32m     32\u001b[0m     q_len \u001b[38;5;241m=\u001b[39m Variable(q_len)  \n\u001b[0;32m---> 34\u001b[0m out,att_out \u001b[38;5;241m=\u001b[39m \u001b[43mnet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43mq\u001b[49m\u001b[43m,\u001b[49m\u001b[43mq_len\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m out \u001b[38;5;241m=\u001b[39m out\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mcpu()\n\u001b[1;32m     36\u001b[0m _, answer5 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtopk(out,\u001b[38;5;241m5\u001b[39m)\n",
      "Cell \u001b[0;32mIn[49], line 50\u001b[0m, in \u001b[0;36mmodel7.forward\u001b[0;34m(self, v, q, q_len)\u001b[0m\n\u001b[1;32m     47\u001b[0m q \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtext(q, \u001b[38;5;28mlist\u001b[39m(q_len\u001b[38;5;241m.\u001b[39mdata))\n\u001b[1;32m     49\u001b[0m v \u001b[38;5;241m=\u001b[39m v \u001b[38;5;241m/\u001b[39m (v\u001b[38;5;241m.\u001b[39mnorm(p\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, keepdim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m.\u001b[39mexpand_as(v) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1e-8\u001b[39m)\n\u001b[0;32m---> 50\u001b[0m a \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattention\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     51\u001b[0m v \u001b[38;5;241m=\u001b[39m apply_attention(v, a)\n\u001b[1;32m     53\u001b[0m combined \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([v, q], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[49], line 109\u001b[0m, in \u001b[0;36mAttention.forward\u001b[0;34m(self, v, q)\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, v, q):\n\u001b[0;32m--> 109\u001b[0m     v \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mv_conv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    110\u001b[0m     q \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mq_lin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdrop(q))\n\u001b[1;32m    111\u001b[0m     q \u001b[38;5;241m=\u001b[39m tile_2d_over_nd(q, v)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/conv.py:463\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 463\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/conv.py:459\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    456\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[1;32m    457\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    458\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[0;32m--> 459\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    460\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected 3D (unbatched) or 4D (batched) input to conv2d, but got input of size: [1, 2560]"
     ]
    }
   ],
   "source": [
    "demo('COCO_val2014_000000001436.jpg','What race is the man in the front with glasses?')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "9e664a9c-246b-4ac2-8cf0-4fee9411a9b3",
   "metadata": {
    "id": "9e664a9c-246b-4ac2-8cf0-4fee9411a9b3",
    "outputId": "e4b9ef5c-a4f2-4d9e-97cd-87dda41b66b1",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Question asked was:  What is he lying on?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4706/3926530035.py:84: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
      "  init.xavier_uniform(self.embedding.weight)\n",
      "/tmp/ipykernel_4706/3926530035.py:42: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
      "  init.xavier_uniform(m.weight)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b7\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected 3D (unbatched) or 4D (batched) input to conv2d, but got input of size: [1, 2560]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[62], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdemo\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/COCO_val2014_000000001436.jpg\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mWhat is he lying on?\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[59], line 34\u001b[0m, in \u001b[0;36mdemo\u001b[0;34m(img_path, question)\u001b[0m\n\u001b[1;32m     31\u001b[0m     q \u001b[38;5;241m=\u001b[39m Variable(q)\n\u001b[1;32m     32\u001b[0m     q_len \u001b[38;5;241m=\u001b[39m Variable(q_len)  \n\u001b[0;32m---> 34\u001b[0m out,att_out \u001b[38;5;241m=\u001b[39m \u001b[43mnet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43mq\u001b[49m\u001b[43m,\u001b[49m\u001b[43mq_len\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m out \u001b[38;5;241m=\u001b[39m out\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mcpu()\n\u001b[1;32m     36\u001b[0m _, answer5 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtopk(out,\u001b[38;5;241m5\u001b[39m)\n",
      "Cell \u001b[0;32mIn[49], line 50\u001b[0m, in \u001b[0;36mmodel7.forward\u001b[0;34m(self, v, q, q_len)\u001b[0m\n\u001b[1;32m     47\u001b[0m q \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtext(q, \u001b[38;5;28mlist\u001b[39m(q_len\u001b[38;5;241m.\u001b[39mdata))\n\u001b[1;32m     49\u001b[0m v \u001b[38;5;241m=\u001b[39m v \u001b[38;5;241m/\u001b[39m (v\u001b[38;5;241m.\u001b[39mnorm(p\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, keepdim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m.\u001b[39mexpand_as(v) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1e-8\u001b[39m)\n\u001b[0;32m---> 50\u001b[0m a \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattention\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     51\u001b[0m v \u001b[38;5;241m=\u001b[39m apply_attention(v, a)\n\u001b[1;32m     53\u001b[0m combined \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([v, q], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[49], line 109\u001b[0m, in \u001b[0;36mAttention.forward\u001b[0;34m(self, v, q)\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, v, q):\n\u001b[0;32m--> 109\u001b[0m     v \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mv_conv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    110\u001b[0m     q \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mq_lin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdrop(q))\n\u001b[1;32m    111\u001b[0m     q \u001b[38;5;241m=\u001b[39m tile_2d_over_nd(q, v)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/conv.py:463\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 463\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/conv.py:459\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    456\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[1;32m    457\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    458\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[0;32m--> 459\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    460\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected 3D (unbatched) or 4D (batched) input to conv2d, but got input of size: [1, 2560]"
     ]
    }
   ],
   "source": [
    "demo('/COCO_val2014_000000001436.jpg', 'What is he lying on?')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c7ba215-186a-4ac9-afd1-40dce505c447",
   "metadata": {
    "id": "5c7ba215-186a-4ac9-afd1-40dce505c447",
    "outputId": "5b424c63-6106-4224-8b4b-2a4474805b48",
    "tags": []
   },
   "outputs": [],
   "source": [
    "demo('download.jpeg','what they are doing?')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4470460-c30d-4ad0-aefe-91bd3f2660c7",
   "metadata": {
    "id": "a4470460-c30d-4ad0-aefe-91bd3f2660c7",
    "outputId": "043d667d-73b8-47d8-da33-3497cc408510",
    "tags": []
   },
   "outputs": [],
   "source": [
    "demo('random-acts-of-kindness-article-1200x800.jpg','what are they carring?')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f26238f5-6248-4681-85d9-30e672d6ce02",
   "metadata": {
    "id": "f26238f5-6248-4681-85d9-30e672d6ce02",
    "outputId": "c31d8aa6-caa2-4f17-d0df-154e1cea1b65",
    "tags": []
   },
   "outputs": [],
   "source": [
    "demo('images.jpeg','where is the chair?')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d59001-da31-427e-98db-a87b207b607e",
   "metadata": {
    "id": "21d59001-da31-427e-98db-a87b207b607e",
    "outputId": "f50ff834-a90e-4019-ba14-5ae1f994b6db",
    "tags": []
   },
   "outputs": [],
   "source": [
    "demo('photographer-rock-15840594.jpg','what does he do?')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55044b8b-9daa-49e8-81e9-c988103d84e5",
   "metadata": {
    "id": "55044b8b-9daa-49e8-81e9-c988103d84e5",
    "outputId": "4a28540a-fc4b-4bf5-b80e-bb46e655dedf",
    "tags": []
   },
   "outputs": [],
   "source": [
    "demo('photographer-rock-15840594.jpg','describe the weather')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44819177-403b-4dde-bc5e-1b17cec89507",
   "metadata": {
    "id": "44819177-403b-4dde-bc5e-1b17cec89507",
    "outputId": "524aef8c-c0ce-4774-a215-f47ee3d6d771",
    "tags": []
   },
   "outputs": [],
   "source": [
    "demo('photographer-rock-15840594.jpg','describe the weather')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "310199cd-435e-4c34-8a52-097eb0257133",
   "metadata": {
    "id": "310199cd-435e-4c34-8a52-097eb0257133"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
